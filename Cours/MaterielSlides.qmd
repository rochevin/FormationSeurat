---
title: "Materiel pour slides"
format:
  html:
    toc: true
    toc-depth: 2
    toc-location: left
    number-sections: true
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
execute:
  cache: true
---


# Introduction

### bulk RNA-seq vs single-cell RNAseq

![bulkRNAseq](images/BulkRNA.png)

![scRNAseq](images/singlecell.png)

![bulk vs scRNAseq](images/scRNAseq.png)

### scRNAseq data

- $C$ cells, $G$ genes:  $C\leq G$ or $C \approx G$ $\Longrightarrow$ high dimensionality
- Measures: $y_{cg}\in\mathbb{N}$  = count expression measure of gene $g$ in cell $c$
- Technical and biological noise
- High variability
- Zero-inflated data $\Longrightarrow$ "sparsity" 
($\geq 80\%$ of zeros per raw, dropouts). 

### Biological questions

:::: {.columns}
::: {.column width="50%"}
- Are there distinct subpopulations of cells? - For each cell type, what are the marker genes? 
- How visualize the cells? 
- Are there continuums of differentiation / activation cell states? 
- ...
:::
::: {.column width="50%"}
![](images/QBio.jpg)
(\tiny Rostom et al, FEBS 2017)
:::
:::


### Statistical analysis
:::: {.columns}
::: {.column width="50%"}
- Clustering of cells 
- Variable (gene) selection in learning or differential analysis (hypothesis testing) 
- Reduction dimension 
- Network inference
- Pseudo-time inference
- ...
:::
::: {.column width="50%"}
![](images/QBio.jpg)
(\tiny Rostom et al, FEBS 2017)
:::
:::

### Number of available tools for scRNAseq data
:::: {.columns}
::: {.column width="50%"}
![](images/Nbtools.png)
:::
::: {.column width="50%"}
![](images/LogoscRNAtools.png)
Many packages are released regularly for scRNAseq data analysis.
You can follow the news in the "Updates" section of scRNA-tools.
<!--
\underline{\url{https://www.scrna-tools.org/updates}}} 
-->
:::
:::
![](images/Nbtools2.png)


### Some bio-info-stat. pipelines/workflows

:::: {.columns}
::: {.column width="50%"}
- [Seurat](https://satijalab.org/seurat/) <!--\cite{Satija15}-->
![](images/Seurat.png)


- [SCANPY](https://github.com/theislab/Scanpy)<!--\cite{scanpy:wolf18}-->
![](images/Scanpy.png)

- [Sincell](https://bioconductor.org/packages/release/bioc/html/sincell.html) 
<!--\cite{Sincell15} -->	![](images/sincell.png)

- [simpleSingleCell](https://bioconductor.org/packages/release/workflows/html/simpleSingleCell.html)
<!--\cite{LunWorkflow16}-->
![](images/WorkflowLun.png)
![](images/simpleSingleCell.png)
:::
::: {.column width="50%"}
- [SINCERA](https://research.cchmc.org/pbge/sincera.html)    
<!--\cite{GuoSINCERA15}-->
![](images/SINCERAschema.png)

- [Scedar](https://github.com/logstar/scedar) <!--\cite{scedar}-->
![](images/Scedar.png)

- $\ldots$
:::
:::


# Preparation des données

## Alignement - filtrage CellRanger

### CellRanger

![](images/10XGenomics.png)
![](images/CellRanger-1.png)
![](images/CellRanger-Pos.png)

## Seurat / scanpy / ...

-   Expliquer que chaque pipeline a son type d'Objet
    -   Seurat en R $\longrightarrow$ Seurat Object
    -   Scanpy en python $\longrightarrow$ AnnData class
-   Dans la suite on va travailler avec Seurat
-   création de l'objet Seurat (SO) pour démarrer schéma évolutif de ce que l'on a rempli dans l'object




### Seurat object

### Example

```{r init}
#| message: false
#| warning: false
library(dplyr)
library(Seurat)
library(patchwork)

# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "data/pbmc3k_filtered_gene_bc_matrices/filtered_gene_bc_matrices/hg19/")

# Initialize the Seurat object with the raw (non-normalized data).
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k", min.cells = 3, min.features = 200)
pbmc
```

On peut montrer le contenu stocké vis-à-vis d'un schéma sur la structure de SO

```{r}
class(pbmc)
dim(pbmc)

pbmc@assays$RNA$counts[10:20,1:15]
Assays(pbmc)
```


# Pipeline d'analyse d'une condition biologique

## Normalisation et contrôle qualité

### QC metrics

- Il y a déjà par défaut à la création de l'objet **SO**, le calcul de nCount_RNA et nFeature_RNA disponible dans meta.data

  + orig.ident: this often contains the sample identity if known,        but will default to project as we had assigned it
  + nCount_RNA: number of UMIs per cell
  + nFeature_RNA: number of genes detected per cell

```{r}
pbmc@meta.data[1:10,]
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA"), ncol = 2)
```

- Calculate some additional metrics for plotting:

  + number of genes detected per UMI: this metric with give us an idea of the complexity of our dataset (more genes detected per UMI, more complex our data)
  
```{r}
pbmc$log10GenesPerUMI <- log10(pbmc$nFeature_RNA) / log10(pbmc$nCount_RNA)
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA","log10GenesPerUMI"), ncol = 3)
```
  
  
  + mitochondrial ratio: this metric will give us a percentage of cell reads originating from the mitochondrial genes
The number of genes per UMI for each cell is quite easy to calculate, and we will log10 transform the result for better comparison between samples. function PercentageFeatureSet() 

```{r}
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, 
                                             pattern = "^MT-")
head(pbmc@meta.data, 5)
VlnPlot(pbmc, features = c("percent.mt"))
```

```{r}
plot1 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot1 + plot2
```

### Selecting cells

Filtrage préliminaire des cellules à l'aide de ces indicateurs

```{r}
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)
dim(pbmc)
```


### Normalisation

#### Why do we need to normalize the data ?

- We need to remove technical biases in order to 
  + to be able to compare cells
  
![](images/motivNormalisation.png)
Images from https://www.biostars.org/p/349881/

The 2 libraries have the same RNA composition.
But the condition B has 3 times more reads than
the condition A.
We need to correct for differences in library size.

  + to be able to compare genes
  
- Take into account the sparsity of the count matrix  

#### Solutions

- Many possible strategies for normalized data
- In Seurat:

  + "LogNormalize" : dans option normalization.method
Feature counts for each cell are divided by the total counts for that cell and multiplied by the scale.factor. This is then natural-log transformed using log1p

  + "CLR": dans option normalization.method
Applies a centered log ratio transformation

  + "RC" : dans option normalization.method
Relative counts. Feature counts for each cell are divided by the total counts for that cell and multiplied by the scale.factor. No log-transformation is applied. For counts per million (CPM) set scale.factor = 1e6

  + "SCTransform" : il faut passer par une autre fonction `SCTransform()`
  The use of SCTransform replaces the need to run NormalizeData, FindVariableFeatures, or ScaleData (described below.)


  
```{r}
 pbmc <- NormalizeData(pbmc, 
                       normalization.method = "LogNormalize",      scale.factor = 10000)
pbmc@assays$RNA$data[10:20,1:10]
# pbmc[["RNA"]]$data[10:20,1:10]
# dim(pbmc[["RNA"]]$data)


# pbmc2<-SCTransform(pbmc) ?????? Ne pas développer SCTransform 
```
  
### HVG

- Identification of highly variable features
- Exhibit high cell-to-cell variation in the dataset 

![](captureContent/ExplicationHVG-Seurat.png) 

Stuart et al. (Cell, 2019). Comprehensive Integration of Single-Cell Data 

Dans la fonction FindVariableFeatures, option selection.method

- "vst": First, fits a line to the relationship of log(variance) and log(mean) using local polynomial regression (loess). Then standardizes the feature values using the observed mean and expected variance (given by the fitted line). Feature variance is then calculated on the standardized values after clipping to a maximum (see clip.max parameter).

- "mean.var.plot" (mvp): First, uses a function to calculate average expression (mean.function) and dispersion (dispersion.function) for each feature. Next, divides features into num.bin (default 20) bins based on their average expression, and calculates z-scores for dispersion within each bin. The purpose of this is to identify variable features while controlling for the strong relationship between variability and average expression

- "dispersion" (disp): selects the genes with the highest dispersion values

```{r}
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)

# Identify the 10 most highly variable genes
top10<-head(VariableFeatures(pbmc), 10)
top10

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot2
```



## Réduction de dimension

### Objectifs de la réduction de dimension

- Minimize curse of dimensionality\vspace*{0.3cm}
- Allow visualization\vspace*{0.3cm}
- Reduce computational time\vspace*{0.3cm}
- \ldots \vspace*{0.3cm}
- But beware of the interpretations after!\vspace*{0.3cm}


### Scaling the data

Vignette Seurat: 

- Shifts the expression of each gene, so that the mean expression across cells is 0
- Scales the expression of each gene, so that the variance across cells is 1
This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
- The results of this are stored in pbmc[["RNA"]]$scale.data
By default, only variable features are scaled.
You can specify the features argument to scale additional features

```{r}
pbmc<-ScaleData(pbmc)
Layers(pbmc[["RNA"]])
pbmc[["RNA"]]$scale.data[10:20,1:10]
```

### Several methods

Several methods are available:
- PCA, 
- t-SNE, 
- UMAP, 
- ZIFA, 
- ZINB-WaVe, 
- SWNE, 
- Diffusion MAP, 
- pCMF, 
- $\ldots$ 

Comparaison des rendus avec [Sleepwalk](https://anders-biostat.github.io/sleepwalk/#)


### Principle of PCA
-   explication du principe de la PCA

### PCA with Seurat

-   scale + runPCA()
-   explication des sorties de Seurat
-   expliquer où c'est stocké dans l'objet

```{r}
#| message: false
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))
pbmc@reductions$pca
str(pbmc@reductions$pca)
head(pbmc@reductions$pca@cell.embeddings)    #head(pbmc[["pca"]]@cell.embeddings)
#head(Embeddings(pbmc@reductions$pca))
head(pbmc@reductions$pca@feature.loadings)
```

- cell.embedding : coordonnées des projections des cellules sur les différents axes princpaux
- feature.loadings : correlations entre genes et composantes principales

```{r}
library(corrplot)
corrplot(pbmc[["pca"]]@feature.loadings[c("CST3", "TYROBP", "LST1", "AIF1", "FTL"),1:5],method="ellipse")
```

```{r}
print(pbmc[["pca"]], dims = 1:3, nfeatures = 5)
```

```{r}
VizDimLoadings(pbmc, dims = 1:2, reduction = "pca")
```

```{r}
DimPlot(pbmc, reduction = "pca") + NoLegend()
```

```{r}
DimHeatmap(pbmc, dims = 1:2, cells = 500, balanced = TRUE)
```

```{r}
ElbowPlot(pbmc)
```

### t-SNE

t-Distributed stochastic neighbor embedding is a state-of-the-art dimensionality reduction algorithm for non-linear data representation that produces a low-dimensional distribution of high-dimensional data (Maaten and Hinton, 2008; Van Der Maaten, 2014). It excels at revealing local structure in high-dimensional data. t-SNE is based on the SNE (Hinton and Roweis, 2002), which starts from converting the high-dimensional Euclidean distances between data points into conditional probabilities that represent similarities. The main idea and the modifications of t-SNE are (1) the symmetric version of SNE and (2) using a Student’s t distribution to compute the similarity between two points in the low-dimensional space.

![](images/schemetSNE.png)


```{r}
#| message: false
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- RunTSNE(pbmc, dims = 1:10)
DimPlot(pbmc, reduction = "tsne")
```


### UMAP

-   utilise au démarrage les coordonnées de PCA
-   explication du principe de l'UMAP
-   illustration

Uniform manifold approximation and projection is a dimension reduction technique that can be used not only for visualization similarly to t-SNE but also for general non-linear dimension reduction. Compared with t-SNE, UMAP retains more global structure with superior run-time performance (McInnes et al., 2018; Becht et al., 2019).

The algorithm is based on three assumptions about the data: (a) the data are uniformly distributed on the Riemannian manifold; (b) the Riemannian metric is locally constant (or can be approximated); and (c) the manifold is locally connected. According to these assumptions, the manifold with fuzzy topology can be modeled. The embedding is found by searching the low-dimensional projection of the data with the closest equivalent fuzzy topology. In terms of model construction, UMAP includes two steps: (1) building a particular weighted k-neighbor graph using the nearest-neighbor descent algorithm (Dong et al., 2011) and (2) computing a low-dimensional representation which can preserve desired characteristics of this graph.

https://www.youtube.com/watch?v=jth4kEvJ3P8


```{r}
#| message: false
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- RunUMAP(pbmc, dims = 1:10)
DimPlot(pbmc, reduction = "umap")
```


## Clustering

### Principe / objectif du clustering

- Goal : organizing cells into groups whose members are similar in some way 
- Fundamental question : What is meant by "similar cells"? 
- The number of clusters $K$ is unknown 
- Typical clustering methods : 
	+ Hierarchical clustering (CAH)
	+ Kmeans clustering
	+ Graph-based clustering
	+ Model-based clustering 
	+ ...


### Some methods

<!--
\textcolor{blue}{\tiny \cite{Duo18}}\\
\textcolor{blue}{\tiny \cite{Freytag18}}\\
\textcolor{blue}{\tiny \cite{petegrosso2019}}\\ 
\textcolor{blue}{\tiny \cite{zhang2020review}}
-->

![](images/TableauReviewMethodesClust.png)

### Dans Seurat

- Calculate k-nearest neighbors and construct the SNN graph
(based on Euclidean distance in PCA space)
- Optimize a modularity function to determine clusters - Louvain’s
algorithm
- Sensitive choice of the resolution parameter
(involve the number of clusters K)

-   explication du principe de Louvain
![](images/Louvain.png)
-   nécessite un parametre de résolution (pas nb de clusters K)
-   exemple pour une valeur de résolution (FindNeighbour + FindCluster)
-   exemple de plot sur UMAP, effectifs par classe, ....

```{r}
pbmc <- FindClusters(pbmc, resolution = 0.5)
table(pbmc@meta.data$seurat_clusters)
DimPlot(pbmc, reduction = "umap") # par défaut il colore par seurat_clusters qui n'existait pas avant ?!
```

### Choix de la resolution ?

- faire tourner pour plusieurs résolution
- visualisation par ARI, clustree des différents clusterings obtenus
- En afficher deux sur UMAP figue dissociée
- on peut tous les stocker dans objet SO mais attention à bien positionner celui étudié pour la suite

```{r}
list_resolutions<-seq(0.1,1,by=0.1)
for (r in list_resolutions){
    pbmc <- FindClusters(pbmc, resolution = r, cluster.name = paste0("Clusters_", r))
}
head(pbmc@meta.data)
```

```{r}
#| message: false

# Visualisation ARI - fonctions auxiliaires
source("Cours/FunctionsAux.R")
ari_matrix <- ARI_matrix(pbmc, list_resolutions)
heatmapari(ari_matrix, list_resolutions)

# Nb de clusters
NbCluster_gg(pbmc, list_resolutions)

# Comparaison visuelle des clusterings obtenus
p1<-DimPlot(pbmc,reduction = "umap",group.by = "Clusters_0.3")
p2<-DimPlot(pbmc,reduction = "umap",group.by = "Clusters_0.4")
p1+p2

# clustree
library(clustree)
clusterplot<-clustree(pbmc, prefix = "Clusters_")
clusterplot
```

Dans la suite, on va se focaliser sur le clustering obtenu avec la resolution 0.5

```{r}
Idents(pbmc)<-pbmc@meta.data$Clusters_0.5
table(Idents(pbmc))
EffPlot(pbmc,resolution=0.5)
pbmc$seurat_clusters<-pbmc@meta.data$Clusters_0.5
```


## Marker gene

### Question / objectif

- formalisation du problème
- naturellement on est sur une question de test

- Aim: After the identification of cell clusters, we want to find marker genes for each cluster
- marker gene for one cluster $\mathcal C_k$: differential expressed gene for this single cluster $\mathcal G_1 = \mathcal C_k$ (specified in ident.1), compared to all other cells $\mathcal G_2 = \{1,\ldots,n\} \backslash \mathcal C_k$.

- FindMarkers() et FindAllMarkers()

### Wilcoxon

- explication du test de Wilcoxon

For a fixed gene $g$, 2 samples
$\underline{X}=(X_{gc}; c\in\mathcal G_1)$ and $\underline{Y}=(X_{gc}; c\in\mathcal G_2)$

Are these two samples equally distributed or not? 

```{r,echo=F}
pbmcaux<-pbmc
pbmcaux$aux<-pbmc$Clusters_0.5
pbmcaux$aux[pbmc$Clusters_0.5==3]<-"3"
pbmcaux$aux[pbmc$Clusters_0.5!=3]<-"0"
Idents(pbmcaux)<-pbmcaux$aux
RidgePlot(pbmcaux,features=c("CD79A","GNG5"))
```

- correction de test multiple
Dans Seurat, Bonferroni

- sur l'exemple, montrer le grand nombre de gènes sélectionnés

```{r}
GeneMkWilcox3<-FindMarkers(pbmc,test.use = "wilcox",ident.1 = 3,logfc.threshold=0.5)
head(GeneMkWilcox3)
sum(GeneMkWilcox3$p_val_adj<0.01)
```


### Problème de double-dipping

- mettre l'exemple classique sur une classe gaussienne

![](images/doubledipping.png)

- reste un probleme ouvert en statistique, loin d'une solution pour le scRNAseq

### AUC (area under the ROC curve) 

- explication de l'AUC. ($2\times |\mbox{AUC}-0.5|$ )
- attention ce n'est pas un test
- choix du seuil ?

![](images/AUROC1.png)
![](images/AUC.png)


- application sur l'exemple avec FindMarkers

```{r}
GeneMkAUC3<-FindMarkers(pbmc,test.use = "roc",ident.1 = 3,logfc.threshold=0.5)
head(GeneMkAUC3)
```

### Autres indicateurs dispo

- pct.1 / pct.2 : pct1 and pct2 : $\%$ of cells where the gene is expressed in each group
- log2FC (avg$\_$logFC) = log fold-change of the average expression between the two groups
- Choice of thresholds ?

```{r}
head(GeneMkAUC3)
```



### Exemple

- on fusionne les deux tableaux obtenus par AUC et wilcox
- on applique des filtres pour retenir un groupe de genes marqueurs pour chaque cluster
- visualisation par DoHeatmap
- dotPlot
- ridgePlot


```{r}
GeneMkAUC3$gene<-rownames(GeneMkAUC3)
GeneMkWilcox3$gene<-rownames(GeneMkWilcox3)
GeneMkCl3_merge<-merge(GeneMkAUC3,GeneMkWilcox3[,c(1,5,6)],by="gene")
head(GeneMkCl3_merge)
```


```{r}
SelectGene<-GeneMkCl3_merge%>%
    filter(myAUC>0.9)%>%
    filter(avg_log2FC>2)%>%
    arrange(desc(myAUC))
```

```{r}
VlnPlot(pbmc, features = SelectGene$gene[1:3], layer = "counts", log = TRUE)
VlnPlot(pbmc, features = SelectGene$gene[1:3], layer = "data", log = TRUE)
```

```{r}
FeaturePlot(pbmc, features = SelectGene$gene[1:3])
```

```{r}
DotPlot(pbmc,features = SelectGene$gene[1:3])
```


### Exemple complet

- reprise avec la fonction FindAllMArkers() pour le faire automatiquement pour toutes les classes. 

```{r,eval=F}
GeneMkWilcox<-FindAllMarkers(pbmc,logfc.threshold = 0.1,test.use = "wilcox")
saveRDS(GeneMkWilcox, file = "data/GeneMkWilcox.rds")
GeneMkAUC<-FindAllMarkers(pbmc,logfc.threshold = 0.1,test.use = "roc")
saveRDS(GeneMkAUC, file = "data/GeneMkAUC.rds")
```

```{r}
GeneMkWilcox<-readRDS("data/GeneMkWilcox.rds")
GeneMkWilcox$gene<-rownames(GeneMkWilcox)
head(GeneMkWilcox)

GeneMkAUC<-readRDS("data/GeneMkAUC.rds")
GeneMkAUC$gene<-rownames(GeneMkAUC)
head(GeneMkAUC)

## PB de merge car gene et cluster ! A revoir
GeneMk_merge<-merge(GeneMkAUC,GeneMkWilcox[,c(1,5,6,7)],by="gene")
head(GeneMk_merge)
```


```{r}
GeneMkAUC %>%
    group_by(cluster) %>%
    arrange(desc(myAUC))%>%
    filter(avg_log2FC > 1) %>%
    slice_head(n = 10) %>%
    ungroup() -> top10
DoHeatmap(pbmc, features = top10$gene) + NoLegend()
```


### 1 groupe contre un autre

- expliquer que l'o peut faire la même chose mais en précisant une classe contre une autre, un groupe de classes contre un autre groupe de classes
- fonction FindMarkers
- le faire sur l'exemple



