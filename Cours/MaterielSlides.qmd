---
title: "Materiel pour slides"
format:
  html:
    toc: true
    toc-depth: 2
    toc-location: left
    number-sections: true
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
execute:
  cache: true
---

<!--
https://nbisweden.github.io/workshop-scRNAseq/home_schedule.html
-->

# Introduction

## Pour suivre la formation

### Installation sur votre ordinateur

Mettre ici les infos pour la mise en place .....

### Packages nécessaires

```{r}
library(Seurat)
library(patchwork)
library(tidyverse)
library(dplyr)
library(corrplot)
library(clustree)
library(SeuratData)
library(reshape2)
library(ggplot2)
library(mvtnorm)
library(FactoMineR)
library(gridExtra)
```

### Objectifs de la formation

A FAIRE


## Qu'est-ce-que les données de single-cell RNA-seq ? 

### bulk RNA-seq vs single-cell RNAseq

- Principe du bulk RNA-seq

![bulkRNAseq](images/BulkRNA.png)
- Principe du single-cell RNA-seq (scRNAseq)

![scRNAseq](images/singlecell.png)

<!--![bulk vs scRNAseq](images/scRNAseq.png)-->


## De la manip à la fin de la bio-informatique 

### Différentes technologies

![](images/type_of_sc_techno.svg)
![](images/sc_applications.svg)

From https://www.nature.com/articles/s41580-023-00615-w



### Alignement - filtrage 

- Après la manip, passage par la bioinformatique
- Alignement des séquences, analyse des cellules que l'on peut retenir, ....

### Avec CellRanger

![](images/10XGenomics.png)
![](images/CellRanger-1.png)
![](images/CellRanger-Pos.png)

https://www.10xgenomics.com/support/software/cell-ranger/latest/algorithms-overview/cr-gex-algorithm

![](images/CellRanger-V2.png)

![](images/gex-algo-pipeline.png)
![](images/SC3pGEX-algo-diagram.png)


Les étapes importantes :

- Trimming des reads
- Demultiplexage - Stockage des UMIs
- Alignement
- UMI counting

![](https://data-science-sequencing.github.io/Win2018/assets/lecture16/biasedreads2.png)

### Others

https://salmon.readthedocs.io/en/latest/alevin.html
https://umi-tools.readthedocs.io/en/latest/index.html

### Après la bio-informatique

https://satijalab.org/seurat/reference/read10x

- 3 fichiers : features, barcode et table de comptage

Pour alvin : 

- _quants_mat.gz_ – Compressed count matrix.
- _quants_mat_cols.txt_ – Column Header (Gene-ids) of the matrix.
- _quants_mat_rows.txt_ – Row Index (CB-ids) of the matrix.
- _quants_tier_mat.gz_ – Tier categorization of the matrix.


Need `tximport`:

```
# Reading in the alevin quants quants
txi <- tximport(files, type="alevin")
```

## De la question bio à la question stat

### Biological questions

:::: {.columns}
::: {.column width="50%"}
- Are there distinct subpopulations of cells? 
- For each cell type, what are the marker genes? 
- How visualize the cells? 
- Are there continuums of differentiation / activation cell states? 
- ...
:::
::: {.column width="50%"}
![](images/QBio.jpg)
(\tiny Rostom et al, FEBS 2017)
:::
:::


### Statistical analysis
:::: {.columns}
::: {.column width="50%"}
- Clustering of cells 
- Variable (gene) selection in learning or differential analysis (hypothesis testing) 
- Reduction dimension 
- Network inference
- Pseudo-time inference
- ...
:::
::: {.column width="50%"}
![](images/QBio.jpg)
(\tiny Rostom et al, FEBS 2017)
:::
:::

## Les packages pour analyser les données de scRNAseq

### Number of available tools for scRNAseq data
:::: {.columns}
::: {.column width="50%"}
![](images/Nbtools.png)
:::
::: {.column width="50%"}
![](images/LogoscRNAtools.png)
Many packages are released regularly for scRNAseq data analysis.
You can follow the news in the "Updates" section of scRNA-tools.
<!--
\underline{\url{https://www.scrna-tools.org/updates}}} 
-->
:::
:::
![](images/Nbtools2.png)


### Some bio-info-stat. pipelines/workflows

:::: {.columns}
::: {.column width="50%"}
- [Seurat](https://satijalab.org/seurat/) <!--\cite{Satija15}-->
![](images/Seurat.png)


- [SCANPY](https://github.com/theislab/Scanpy)<!--\cite{scanpy:wolf18}-->
![](images/Scanpy.png)

- [Sincell](https://bioconductor.org/packages/release/bioc/html/sincell.html) 
<!--\cite{Sincell15} -->	![](images/sincell.png)

- [simpleSingleCell](https://bioconductor.org/packages/release/workflows/html/simpleSingleCell.html)
<!--\cite{LunWorkflow16}-->
![](images/WorkflowLun.png)
![](images/simpleSingleCell.png)
:::
::: {.column width="50%"}
- [SINCERA](https://research.cchmc.org/pbge/sincera.html)    
<!--\cite{GuoSINCERA15}-->
![](images/SINCERAschema.png)

- [Scedar](https://github.com/logstar/scedar) <!--\cite{scedar}-->
![](images/Scedar.png)

- $\ldots$
:::
:::

### Attention au type d'objet

-   Expliquer que chaque pipeline a son type d'Objet
    -   Seurat en R $\longrightarrow$ Seurat Object
    -   Scanpy en python $\longrightarrow$ AnnData class
    -   SingleCellExperiment 
- Il existe des fonctions qui permettent de passer de l'un à l'autre

- Dans la suite on va travailler avec Seurat

A VOIR COMMENT ON ARTICULE AVEC AnnData juste après. 
Peut-etre le mettre dans pour aller plus loin quand on veut basculer dans scanpy et/ou quand on doit passer par sce.  

### AnnData

![Représentation schématique de l'objet AnnData](images/anndata_schema.svg){width="50%" fig-align:"center"}

* `X`: Données de comptage sous forme de matrice creuse (sparse):
  * ```python
  adata.X
  <100x2000 sparse matrix of type '<class 'numpy.float32'>'
	with 126526 stored elements in Compressed Sparse Row format>
    ```
  * ```python
  adata.obs_names = [f"Cell_{i:d}" for i in range(adata.n_obs)]
  adata.var_names = [f"Gene_{i:d}" for i in range(adata.n_vars)]
  print(adata.obs_names[:10])
  Index(['Cell_0', 'Cell_1', 'Cell_2', 'Cell_3', 'Cell_4', 'Cell_5', 'Cell_6',
       'Cell_7', 'Cell_8', 'Cell_9'],
      dtype='object')
    ```
* `obs`/`var`: Metadonnées des observations variables 
* `Layers`: `adata.layers["log_transformed"] = np.log1p(adata.X)`
* `obsm`/`varm` : Métriques ou des données dérivées supplémentaires liées aux observations / variables (Résultat ACP)
* `uns`: Données non structurées (paramètres de l'analyse, autres métadonnées, ...)
* `obsp`/`varp`: Relations par paires entre les cellules


## Exemple pour la suite

### Présentation des données

- Données de Peripheral Blood Mononuclear Cells (PBMC) de 10X Genomics. 

- 2700 cellules séquencées en Illumina NextSeq 500. 

- Téléchargez le jeu de données [ici](https://satijalab.org/seurat/articles/pbmc3k_tutorial#:~:text=can%20be%20found-,here,-.) ou sur le dépot git de la formation

- Dans le dossier ".../hg19/" on a trois fichiers 
  + barcodes.tsv
  + genes.tsv
  + matrix.mtx


### Création de l'objet Seurat

- On commence par lire les données en sortie de CellRanger de 10X à l'aide de la fonction `Read10X()`. 

- Remarque : pour les formats h5 plus récents, utilisez la fonction `Read10X_h5()`

```{r init}
#| message: false
#| warning: false

# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "data/pbmc3k_filtered_gene_bc_matrices/filtered_gene_bc_matrices/hg19/")
```

- Création ensuite de l'objet Seurat avec `CreateSeuratObject()` :

```{r}
# Initialize the Seurat object with the raw (non-normalized data).
pbmc <- CreateSeuratObject(counts = pbmc.data, 
                           project = "pbmc3k", 
                           min.cells = 3, 
                           min.features = 200)
class(pbmc)
pbmc
```

### Contenu du SO

- $C$= `r ncol(pbmc)` cellules décrites par `$G=$ `r nrow(pbmc)`gènes
- Les comptages bruts sont dans `pbmc@assays$RNA$counts`

```{r}
dim(pbmc)
pbmc@assays$RNA$counts[10:20,1:15]
Assays(pbmc)
```

![](images/SO-1.png)


### Spécificités des données scRNAseq

- $C$ cellules décrites par  $G$ gènes:  $C\leq G$ or $C \approx G$ $\Longrightarrow$ grande dimension
- Mesures: $y_{cg}\in\mathbb{N}$  = count expression measure of gene $g$ in cell $c$. Ce sont des comptages
- Technical and biological noise
- High variability
- Zero-inflated data $\Longrightarrow$ "sparsity" 
($\geq 80\%$ of zeros per raw, dropouts). 


# Pipeline d'analyse d'une condition biologique

## Contrôle qualité

### QC metrics : `nCount_RNA` et `nFeature_RNA`

- A la création de l'objet **SO**, calcul de `nCount_RNA` et `nFeature_RNA`, disponibles dans `meta.data`

 <!-- + orig.ident: this often contains the sample identity if known,        but will default to project as we had assigned it
 -->
 
  + nCount_RNA: number of UMIs per cell
  + nFeature_RNA: number of genes detected per cell

![](images/SO-2.png)


```{r}
head(pbmc@meta.data)
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA"), ncol = 2)
```

**Mettre le schema evolué avec meta.data**

### QC metrics

- Calculate some additional metrics for plotting:

  + number of genes detected per UMI: 
this metric with give us an idea of the complexity of our dataset (more genes detected per UMI, more complex our data)
  
```{r}
pbmc$log10GenesPerUMI <- log10(pbmc$nFeature_RNA) /   log10(pbmc$nCount_RNA)
VlnPlot(pbmc, features = c("log10GenesPerUMI"))
```
  
  
  + mitochondrial ratio: this metric will give us a percentage of cell reads originating from the mitochondrial genes
The number of genes per UMI for each cell is quite easy to calculate, and we will log10 transform the result for better comparison between samples. function `PercentageFeatureSet()` 

```{r}
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, 
                                             pattern = "^MT-")
head(pbmc@meta.data, 5)
VlnPlot(pbmc, features = c("percent.mt"))
```

```{r}
plot1 <- FeatureScatter(pbmc, 
                        feature1 = "nCount_RNA", 
                        feature2 = "percent.mt")
plot2 <- FeatureScatter(pbmc, 
                        feature1 = "nCount_RNA", 
                        feature2 = "nFeature_RNA")
plot1 + plot2
```

![](images/SO-3.png)


### Filtrage des cellules 

- A l'aide de ces indicateurs, filtrage préliminaire des cellules 

```{r}
dim(pbmc)
pbmc <- subset(pbmc, 
               subset = nFeature_RNA > 200 & 
                        nFeature_RNA < 2500 & 
                        percent.mt < 5)
dim(pbmc)
```

On ne conserve que $C=$ `r ncol(pbmc)` cellules pour la suite de l'étude. 


## Normalisation

### Why do we need to normalize the data ?

- We need to remove technical biases in order to 
  + to be able to compare cells
  
![](images/motivNormalisation.png)

Images from https://www.biostars.org/p/349881/

> The 2 libraries have the same RNA composition.
> But the condition B has 3 times more reads than
the condition A.
We need to correct for differences in library size.

  + to be able to compare genes
  
- Take into account the sparsity of the count matrix  

### Normalization in Seurat

- Many possible strategies for normalized data
- In Seurat, function `NormalizeData(object,normalization.method= ...,)`

  + "LogNormalize" : Feature counts for each cell are divided by the total counts for that cell and multiplied by the scale.factor. This is then natural-log transformed using log1p

  + "CLR" : Applies a centered log ratio transformation
  
  >clr_function <- function(x) {
  >        return(log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm   >= TRUE) / length(x = x)))))}
  >log1p(x) computes log(1+x) accurately also for |x| << 1.

  + "RC" (Relative counts): Feature counts for each cell are divided by the total counts for that cell and multiplied by the scale.factor. 
  No log-transformation is applied. 
  For counts per million (CPM) set scale.factor = 1e6

  + "SCTransform" : il faut passer par une autre fonction `SCTransform()`
The use of SCTransform replaces the need to run NormalizeData, FindVariableFeatures, or ScaleData (described below.)
In Seurat v5, SCT v2 is applied by default. You can revert to v1 by setting vst.flavor = 'v1'

<!--
Article: Comparison and evaluation of statistical
error models for scRNA-seq.
Saket Choudhary and Rahul Satija
-->

### Exemple

```{r}
 pbmc <- NormalizeData(pbmc, 
                       normalization.method = "LogNormalize", 
                       scale.factor = 10000)
pbmc@assays$RNA$data[10:20,1:5]
# pbmc[["RNA"]]$data[10:20,1:10]
# dim(pbmc[["RNA"]]$data)
```
  
```{r,echo=F}
aux<-data.frame(brut=apply(pbmc@assays$RNA$counts,2,sum),
                norm=apply(pbmc@assays$RNA$data,2,sum))
ggplot(melt(aux),aes(x=variable,y=value))+
  geom_boxplot()
rm(aux)
```
  
![](images/SO-4.png)  
  
  
### Identification des gènes HVG

- HVG = High Variable Gene (feature)

- Identification of highly variable features

- Exhibit high cell-to-cell variation in the dataset 

![](captureContent/ExplicationHVG-Seurat.png) 

> **Feature selection for individual datasets**
In each dataset, we next aimed to identify a subset of features (e.g., genes) exhibiting high variability across cells, and therefore represent heterogeneous features to prioritize for downstream analysis. Choosing genes solely based on their log-normalized single-cell variance fails to account for the mean-variance relationship that is inherent to single-cell RNA-seq. Therefore, we first applied a variance-stabilizing transformation to correct for this [Mayer et al., 2018; Hafemeister and Satija, 2019].

> To learn the mean-variance relationship from the data, we computed the mean and variance of each gene using the unnormalized data (i.e., UMI or counts matrix), and applied log10 transformation to both. We then fit a curve to predict the variance of each gene as a function of its mean, by calculating a local fitting of polynomials of degree 2 (R function loess, span = 0.3). This global fit provided us with a regularized estimator of variance given the mean of a feature. As such, we could use it to standardize feature counts without removing higher-than-expected variation.

> Given the expected variances, we performed the transformation $z_{i,j} = \frac{x_{i,j} - \bar{x}_i}{\sigma_i}$

> where $z_{i,j}$ is the standardized value of feature $i$ in cell $j$, $x_{i,j}$ is the raw value of feature $i$ in cell $j$, $\bar{x}_i$ is the mean raw value for feature $i$, and $\sigma_i$ is the expected standard deviation of feature $i$ derived from the global mean-variance fit. To reduce the impact of technical outliers, we clipped the standardized values to a maximum value of $\sqrt{N}$, where $N$ is the total number of cells. For each gene, we then computed the variance of standardized values across all cells. This variance represents a measure of single-cell dispersion after controlling for mean expression, and we use it directly to rank the features. Unless otherwise noted, we selected the 2,000 genes with the highest standardized variance as “highly variable.” This procedure is implemented in the FindVariableFeatures function in Seurat v3 (selection.method = “vst”).

Stuart et al. (Cell, 2019). Comprehensive Integration of Single-Cell Data 


Dans la fonction `FindVariableFeatures(object,selection.method=...,)` : 

- "vst": First, fits a line to the relationship of log(variance) and log(mean) using local polynomial regression (loess). Then standardizes the feature values using the observed mean and expected variance (given by the fitted line). Feature variance is then calculated on the standardized values after clipping to a maximum (see clip.max parameter).

- "mean.var.plot" (mvp): First, uses a function to calculate average expression (mean.function) and dispersion (dispersion.function) for each feature. Next, divides features into num.bin (default 20) bins based on their average expression, and calculates z-scores for dispersion within each bin. The purpose of this is to identify variable features while controlling for the strong relationship between variability and average expression

- "dispersion" (disp): selects the genes with the highest dispersion values

```{r}
pbmc <- FindVariableFeatures(pbmc, 
                             selection.method = "vst", 
                             nfeatures = 2000)
length(VariableFeatures(pbmc))
# Identification du top 10 des HVG
top10<-head(VariableFeatures(pbmc), 10)
top10
# plot variable features with and without labels
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot2
```



## Réduction de dimension

### Objectifs de la réduction de dimension

- Minimize curse of dimensionality\vspace*{0.3cm}
- Allow visualization\vspace*{0.3cm}
- Reduce computational time\vspace*{0.3cm}
- \ldots \vspace*{0.3cm}
- But beware of the interpretations after!\vspace*{0.3cm}

### Several methods

Several methods are available:

- **PCA**, 
- **t-SNE**, 
- **UMAP**, 
- ZIFA, 
- ZINB-WaVe, 
- SWNE, 
- Diffusion MAP, 
- pCMF, 
- $\ldots$ 

Comparaison des rendus avec [Sleepwalk](https://anders-biostat.github.io/sleepwalk/#)

### Scaling the data

Vignette Seurat: 

- Shifts the expression of each gene, so that the mean expression across cells is 0
- Scales the expression of each gene, so that the variance across cells is 1
This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
- The results of this are stored in pbmc[["RNA"]]$scale.data
By default, only variable features are scaled.
You can specify the features argument to scale additional features

Dans Seurat, fonction `ScaleData()`

```{r}
pbmc<-ScaleData(pbmc) #features = Default is variable features J (=2000 par défaut)
dim(pbmc@assays$RNA$scale.data) # on a plus que J=2000 gènes 
#d'où des soucis (warnings) dans la suite mais c'est plus rapide pour la formation ????
pbmc[["RNA"]]$scale.data[10:20,1:10]
```

![](images/SO-6.png)




### Principe de PCA

- PCA = Principal Component Analysis
- Réduire l'espace tout en conservant "assez dinformation"
- Méthode de réduction linéaire : Les composantes principales (méta-variables) sont des combinaisons linéaires des variables initiales (ici les gènes)
- Correspond à la diagonalisation de la matrice de corrélation (si ACP centrée réduite)
  + valeur propre $\lambda_s$ = inertie des individus projetés sur l'axe porté par un vecteur propre normé associé $v_s$ (axe principal)
  + composante principale $C_s$ contient les coordonnées des projetés des individus sur l'axe engendré par $v_s$

```{r}
#| echo: FALSE
#| fig-height: 4

set.seed(1234)
R<-matrix(c(1,1,-1,1),ncol=2)/sqrt(2)
Sigma<-R%*%diag(c(4,0.5))%*%t(R)
X<-as.data.frame(rmvnorm(50,mean=rep(0,2),sigma=Sigma))
#ggplot(X,aes(x=V1,y=V2))+
#  geom_point()+
#  theme_minimal()+xlab("x")+ylab("y")+xlim(-4,4)+ylim(-5,5)
```

```{r}
#| fig-height: 6
proj<-function(X,a,b,xl,xmin=-4,xmax=4,ymin=-5,ymax=5){
  v<-c(a,b)
  v<-v/sqrt(sum(v^2))
  
  dfline=data.frame(xx=seq(-xl,xl,0.01),yy=(v[2]/v[1]*seq(-xl,xl,0.01)))
  aux<-as.matrix(X)%*%as.matrix(v)
  Y<-matrix(rep(v,each=nrow(X)),ncol=2)
  for (i in 1:nrow(Y))
    Y[i,]<-aux[i]*Y[i,]
  dfproj=data.frame(xp=Y[,1],yp=Y[,2])
  
  line_df <- data.frame(
  x = X[,1],
  y = X[,2],
  xend =Y[,1],
  yend = Y[,2]
  )

  g<-ggplot(X,aes(x=V1,y=V2))+
    geom_point()+
    geom_line(data=dfline,aes(x=xx,y=yy))+
    geom_point(data=dfproj,aes(x=xp,y=yp),col="red")+
    geom_segment(
    data = line_df, 
    mapping = aes(x=x, y=y, xend=xend, yend=yend), 
    inherit.aes = FALSE,linetype="dotted"
  )+
  xlab("")+ylab("")+xlim(xmin,xmax)+ylim(ymin,ymax)+
  ggtitle(paste("Inertie axiale= ",round(sum(diag(var(Y))),2),sep=""))
  return(g)
}

res<-PCA(X,scale.unit = F,graph=F)
g1<-proj(X,a=res$var$coord[1,1],b=res$var$coord[2,1],xl=4)
g2<-proj(X,a=cos(2*pi/3),b=sin(2*pi/3),xl=3)

grid.arrange(g1,g2,ncol=2)
```


```{r}
#| fig.width: 8
#| fig.height: 4 
#| fig.cap: Analyse en composante principale du jeu de données iris sur les deux premières dimensions.
X <- iris[,c(1,3)]
# Run PCA
pca <- princomp(X)
load <- loadings(pca)
slope <- load[2, ] / load[1, ]
cmeans <- apply(X, 2, mean)
intercept <- cmeans[2] - (slope * cmeans[1])


# Plot perpendicular segments

df<-data.frame(X)
img1 <- ggplot(df,aes(Sepal.Length,Petal.Length))+
  geom_point()+
  geom_point(data = cmeans %>% t %>%  as.data.frame(),aes(Sepal.Length,Petal.Length),col="red",size=4) +
  geom_abline(intercept=intercept[1],slope=slope[1],linetype="dashed")+
  geom_abline(intercept=intercept[2],slope=slope[2],linetype="dashed")+
  theme_classic(base_size=16) + coord_fixed()


img2 <- (pca$scores) %>% as.data.frame() %>% ggplot(aes(Comp.1,-1*Comp.2)) + geom_point()+ theme_classic(base_size=16) + geom_vline(xintercept = 0,linetype="dashed")+ geom_hline(yintercept = 0,linetype="dashed")

design <- "AB"
wrap_plots(A=img1,B=img2, design = design,tag_level="new")+  plot_annotation(tag_levels = "A")
```

- Les axes de l'ACP sont projetés sur les dimensions d'origine et passent par la moyenne (rouge).

- Projection des points dans l'espace de l'ACP.

![](images/ACP-Fenelon.png)
![](images/repereACP.png)

### PCA with Seurat

-   L'ACP est faite sur les données centrées réduites à l'aide de la fonction `runPCA()`

```{r}
#| message: false
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))
  #str(pbmc@reductions$pca)
```

- On retrouve les coordonnées des projections des cellules sur les différents axes principaux (composantes principales)

```{r}
head(pbmc@reductions$pca@cell.embeddings)    #head(pbmc[["pca"]]@cell.embeddings)
#head(Embeddings(pbmc@reductions$pca))
```

et visualisation de la projection des cellules dans le premier plan factoriel avec la fonction `DimPlot()` : 

```{r}
DimPlot(pbmc, reduction = "pca") + NoLegend()
```

- Les corrélations entre les gènes et les composantes principales

```{r}
head(pbmc@reductions$pca@feature.loadings)
corrplot(pbmc[["pca"]]@feature.loadings[c("CST3", "TYROBP", "LST1", "AIF1", "FTL"),1:5],method="ellipse")
```

- Gènes les plus corrélés avec les composantes principales : 

```{r}
print(pbmc[["pca"]], dims = 1:3, nfeatures = 5)
VizDimLoadings(pbmc, dims = 1:2, reduction = "pca",nfeatures=20)
```

```{r}
DimHeatmap(pbmc, dims = 1:2, cells = 500, balanced = TRUE)
```

- Pour choisir le nombre de composantes principales à conserver :

```{r}
ElbowPlot(pbmc)
```

Mais probleme de l'ACP sur les données scRNAseq

- C'est une méthode de réduction de dimension linéaire
- Elle est sensible à la sparsité des données scRNAseq 
- C'est utilisé pour réduire le jeu de données pour certaines méthodes dans la suite de l'étude


### t-SNE

- Méthode de réduction de dimension non-linéaire 
(Maaten and Hinton, 2008; Van Der Maaten, 2014)

- 


t-Distributed stochastic neighbor embedding is a state-of-the-art dimensionality reduction algorithm for non-linear data representation that produces a low-dimensional distribution of high-dimensional data (Maaten and Hinton, 2008; Van Der Maaten, 2014). It excels at revealing local structure in high-dimensional data. t-SNE is based on the SNE (Hinton and Roweis, 2002), which starts from converting the high-dimensional Euclidean distances between data points into conditional probabilities that represent similarities. The main idea and the modifications of t-SNE are (1) the symmetric version of SNE and (2) using a Student’s t distribution to compute the similarity between two points in the low-dimensional space.

![](images/schemetSNE.png)

Dans Seurat, en raison de la dimension des données, part avec les données de l'ACP (reduction="pca" par défaut). Détermination des voisins par KNN puis t-SNE avec la fonction `RunTSNE()`

```{r}
#| message: false
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- RunTSNE(pbmc, dims = 1:10)
DimPlot(pbmc, reduction = "tsne")+NoLegend()
```
![](images/SO-8.png)

### UMAP

-   utilise au démarrage les coordonnées de PCA
-   explication du principe de l'UMAP
-   illustration

Uniform manifold approximation and projection is a dimension reduction technique that can be used not only for visualization similarly to t-SNE but also for general non-linear dimension reduction. Compared with t-SNE, UMAP retains more global structure with superior run-time performance (McInnes et al., 2018; Becht et al., 2019).

The algorithm is based on three assumptions about the data: (a) the data are uniformly distributed on the Riemannian manifold; (b) the Riemannian metric is locally constant (or can be approximated); and (c) the manifold is locally connected. According to these assumptions, the manifold with fuzzy topology can be modeled. The embedding is found by searching the low-dimensional projection of the data with the closest equivalent fuzzy topology. In terms of model construction, UMAP includes two steps: (1) building a particular weighted k-neighbor graph using the nearest-neighbor descent algorithm (Dong et al., 2011) and (2) computing a low-dimensional representation which can preserve desired characteristics of this graph.

https://www.youtube.com/watch?v=jth4kEvJ3P8


```{r}
#| message: false
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- RunUMAP(pbmc, dims = 1:10)
DimPlot(pbmc, reduction = "umap")+NoLegend()
```

![](images/SO-9.png)

## Clustering

### Principe / objectif du clustering

- Goal : organizing cells into groups whose members are similar in some way 
- Fundamental question : What is meant by "similar cells"? 
- The number of clusters $K$ is unknown 
- Typical clustering methods : 
	+ Hierarchical clustering (CAH)
	+ Kmeans clustering
	+ Graph-based clustering
	+ Model-based clustering 
	+ ...


### Some methods

<!--
\textcolor{blue}{\tiny \cite{Duo18}}\\
\textcolor{blue}{\tiny \cite{Freytag18}}\\
\textcolor{blue}{\tiny \cite{petegrosso2019}}\\ 
\textcolor{blue}{\tiny \cite{zhang2020review}}
-->

![](images/TableauReviewMethodesClust.png)

### Dans Seurat

- Calculate k-nearest neighbors and construct the SNN graph
(based on Euclidean distance in PCA space)
- Optimize a modularity function to determine clusters - Louvain’s
algorithm
- Sensitive choice of the resolution parameter
(involve the number of clusters K)

-   explication du principe de Louvain
![](images/Louvain.png)
-   nécessite un paramètre de résolution (pas nb de clusters K)
-   Fonctions `FindNeighbour()` puis  `FindCluster()`

### Exemple

- Clustering pour une résolution de $0.5$

```{r}
pbmc <- FindClusters(pbmc, resolution = 0.5)
```

![](images/SO-10.png)

- Analyse du clustering obtenu

```{r}
table(pbmc@meta.data$seurat_clusters)
DimPlot(pbmc, reduction = "umap") # par défaut il colore par seurat_clusters qui n'existait pas avant ?!
```

### Choix de la résolution ?

- Faire tourner pour plusieurs valeurs de résolution

```{r}
list_resolutions<-seq(0.1,1,by=0.1)
for (r in list_resolutions){
    pbmc <- FindClusters(pbmc, resolution = r, cluster.name = paste0("Clusters_", r))
}
head(pbmc@meta.data)
```

- Lien entre les clusterings obtenus via l'indicateur ARI (Adjusted Rand Index) et visuellement avec le package `clustree` par exemple 

```{r}
#| message: false

# Visualisation ARI - fonctions auxiliaires
source("Cours/FunctionsAux.R")
ari_matrix <- ARI_matrix(pbmc, list_resolutions)
heatmapari(ari_matrix, list_resolutions)

# Nb de clusters
NbCluster_gg(pbmc, list_resolutions)

# Comparaison visuelle des clusterings obtenus
p1<-DimPlot(pbmc,reduction = "umap",group.by = "Clusters_0.3")
p2<-DimPlot(pbmc,reduction = "umap",group.by = "Clusters_0.4")
p1+p2

# clustree
clusterplot<-clustree(pbmc, prefix = "Clusters_")
clusterplot
```

- On peut tous les stocker dans objet SO mais attention à bien positionner celui étudié pour la suite avec la fonction `Idents()`. 

```{r}
colnames(pbmc@meta.data)
```


- Pour la suite, on va se focaliser sur le clustering obtenu avec la resolution 0.5.

```{r}
Idents(pbmc)<-pbmc@meta.data$Clusters_0.5
table(Idents(pbmc))
#EffPlot(pbmc,resolution=0.5,clustname="Clusters_0.5")
pbmc$seurat_clusters<-pbmc@meta.data$Clusters_0.5
DimPlot(pbmc,reduction = "umap")
```


## Marker gene

### Formalisation du problème

- Objectif: déterminer les gènes dont l'expression varient entre 2 "groupes" cellulaires ($\mathcal G_1$ et $\mathcal G_2$)

- Gènes marqueurs pour une classe  $\mathcal C_k$: 
$\mathcal G_1 = \mathcal C_k$ et 
$\mathcal G_2 = \{1,\ldots,n\} \backslash \mathcal C_k$

- Côté statistique, c'est un problème de test !

- Fonctions dans `Seurat`: `FindMarkers()` et `FindAllMarkers()`


### Différentes situations

![](images/schemaDE.png)


### Test de Wilcoxon

- Pour un gène $g$ fixé :
 on veut tester s'il y a une différente de distribution de l'expression de ce gène entre deux échantillons 
$\underline{X}^{(1)}=(X_{gc}; c\in\mathcal G_1)$ et 
$\underline{X}^{(2)}=(X_{gc}; c\in\mathcal G_2)$

```{r,echo=F}
pbmcaux<-pbmc
pbmcaux$aux<-pbmc$Clusters_0.5
pbmcaux$aux[pbmc$Clusters_0.5==3]<-"3"
pbmcaux$aux[pbmc$Clusters_0.5!=3]<-"0"
Idents(pbmcaux)<-pbmcaux$aux
RidgePlot(pbmcaux,features=c("CD79A","GNG5"))
```

- Test de Wilcoxon : test non paramétrique basé sur les rangs

-  + Correction de tests multiples (dans Seurat, Bonferroni)


```{r}
GeneMkWilcox3<-FindMarkers(pbmc,
                           test.use = "wilcox",
                           ident.1 = 3,
                           logfc.threshold=0.5)
head(GeneMkWilcox3)
sum(GeneMkWilcox3$p_val_adj<0.01)
```


### Problème de double-dipping

- Beaucoup de gènes marqueurs détectés $\Longrightarrow$ problème de double-dipping

![](images/doubledipping.png)

- Reste un problème ouvert en statistique, loin d'une solution pour le scRNAseq

### Méthode AUC (area under the ROC curve) 

- AUC = area under the ROC curve ($2\times |\mbox{AUC}-0.5|$ )
- Attention, ce n'est pas un test ! 

![](images/AUROC1.png)
![](images/AUC.png)

- Mais difficulté sur le choix du seuil !


```{r}
GeneMkAUC3<-FindMarkers(pbmc,
                        test.use = "roc",
                        ident.1 = 3,
                        logfc.threshold=0.5)
head(GeneMkAUC3)
ggplot(GeneMkAUC3,aes(x=myAUC))+
  geom_density()
```

### Autres indicateurs disponibles

- pct.1 / pct.2 : $\%$ de cellules où le gène $g$ est exprimé ($X_{cg}>0$) dans le groupe $\mathcal G_1$ / $\mathcal G_2$

- avg$\_$log2FC : log2 Fold-Change de l'expression moyenne entre les deux groupes  

- Pour tous ces indicateurs, il faut ensuite faire des choix de seuil

```{r}
head(GeneMkAUC3)
```


### Exemple

- Sélection des gènes marqueurs pour le cluster 3 en appliquant des filtres

```{r}
GeneMkAUC3$gene<-rownames(GeneMkAUC3)
GeneMkWilcox3$gene<-rownames(GeneMkWilcox3)
GeneMkCl3_merge<-merge(GeneMkAUC3,GeneMkWilcox3[,c(1,5,6)],by="gene")
head(GeneMkCl3_merge)
```


```{r}
SelectGene<-GeneMkCl3_merge%>%
    filter(myAUC>0.9)%>%
    filter(avg_log2FC>2)%>%
    arrange(desc(myAUC))
head(SelectGene)
```

- Pour visualiser, on peut s'appuyer sur les fonctions `VlnPlot()`, 
`FeaturePlot()`, `DotPlot()`, `RidgePlot()`

```{r}
VlnPlot(pbmc, features = SelectGene$gene[1:3], layer = "counts", log = TRUE)
VlnPlot(pbmc, features = SelectGene$gene[1:3], layer = "data", log = TRUE)
```

```{r}
FeaturePlot(pbmc, features = SelectGene$gene[1:3])
```

```{r}
DotPlot(pbmc,features = SelectGene$gene[1:3])
```

```{r}
RidgePlot(pbmc,features = SelectGene$gene[1:3])
```


### Gènes marqueurs pour toutes les classes

- Utilisation de la fonction `FindAllMarkers()` pour faire la détection des gènes marqueurs sur toutes les classes (s'appuie sur `FindMarkers()`).

> Attention, ne lancez pas les fonctions suivantes en raison du temps calcul
> Chargez la sauvegarde des fichiers obtenus

```{r,eval=F}
GeneMkWilcox<-FindAllMarkers(pbmc,
                             logfc.threshold = 0.1,
                             test.use = "wilcox")
saveRDS(GeneMkWilcox, file = "data/GeneMkWilcox.rds")
GeneMkAUC<-FindAllMarkers(pbmc,
                          logfc.threshold = 0.1,
                          test.use = "roc")
saveRDS(GeneMkAUC, file = "data/GeneMkAUC.rds")
```

```{r}
GeneMkWilcox<-readRDS("data/GeneMkWilcox.rds")
GeneMkWilcox$gene<-rownames(GeneMkWilcox)
head(GeneMkWilcox)
table(GeneMkWilcox$cluster)
```

```{r}
GeneMkAUC<-readRDS("data/GeneMkAUC.rds")
GeneMkAUC$gene<-rownames(GeneMkAUC)
head(GeneMkAUC)
table(GeneMkAUC$cluster)
```


```{r}
## PB de merge car gene et cluster ! A revoir
## il faut merger les genes pour chaque cluster fixé
    ##GeneMk_merge<-merge(GeneMkAUC,GeneMkWilcox[,c(1,5,6,7)],by="gene")
    ##head(GeneMk_merge)
GeneMk_merge<-GeneMkWilcox%>%
              select(c("p_val","p_val_adj","cluster","gene"))%>%
              left_join(GeneMkAUC,by=c("gene","cluster"))
GeneMk_merge<-GeneMk_merge[,c(4,3,1:2,5:10)]%>%
              arrange(cluster,desc(myAUC))
GeneMk_merge[65:75,]  ## pourquoi ce n'est pas dans GeneMkAUC ???   
```

```{r}
ggplot(GeneMkAUC,aes(x=cluster,y=myAUC))+
  geom_violin(aes(color=cluster))+
  stat_summary(fun.y=function(z) { quantile(z,0.9) }, geom="point", shape=20, size=2)
  #geom_boxplot(width=0.1)
```


```{r}
GeneMkAUC %>%
    group_by(cluster) %>%
    arrange(desc(myAUC))%>%
    filter(avg_log2FC > 1) %>%
    slice_head(n = 10) %>%
    ungroup() -> top10
DoHeatmap(pbmc, features = top10$gene) + NoLegend()
```


### ????

- Dans le cas où les deux groupes sont deux clusters
$$\mathcal G_1 = \mathcal C_k \textrm{ et } \mathcal G_2 = \mathcal C_{k'}$$
- Utilisation de la fonction `FindMarkers()` en précisant `ident.1` et `ident.2`


```{r}
GeneMkCl3vsCl5<-FindMarkers(pbmc,
                  test.use="roc",
                  ident.1=3,
                  ident.2=5,
                  logfc.threshold=0.1)
ggplot(GeneMkCl3vsCl5,aes(x=myAUC))+
  geom_density()
```

```{r}
SelectCl3vsCl5<-GeneMkCl3vsCl5%>%
  filter(myAUC>0.9)%>%
  arrange(desc(avg_log2FC))
head(SelectCl3vsCl5)
```

```{r}
DoHeatmap(pbmc[,which(pbmc$Clusters_0.5 %in% c(3,5))], 
          features = rownames(SelectCl3vsCl5),
          assay = "RNA",slot = "data") + 
  NoLegend()
```

```{r}
FeaturePlot(pbmc, features = rownames(SelectCl3vsCl5)[1:3])
```

```{r}
DotPlot(pbmc,features = rownames(SelectCl3vsCl5)[1:10])+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}
RidgePlot(pbmc,features = rownames(SelectCl3vsCl5)[1])
```

# Pipeline d'analyse pour deux (plusieurs) conditions biologiques

### Plusieurs types d'intégration

![](images/IntegHorizontal.png)
![](images/IntegVertical.png)


### Integration horizontale

![](images/integ2.png)

### REM

A réfléchir : 

- Si on a deux fichiers de données diff --> 2 objets Seurat normalisés séparément puis intégration
- Dans l'exemple ifnb c'est sous forme de layers (Seurat V5)

<!--
https://nbisweden.github.io/workshop-scRNAseq/labs/seurat/seurat_03_integration.html
-->

### Example

The object contains data from human PBMC from two conditions, interferon-stimulated and control cells (stored in the stim column in the object metadata). We will aim to integrate the two conditions together, so that we can jointly identify cell subpopulations across datasets, and then explore how each group differs across conditions

In previous versions of Seurat, we would require the data to be represented as two different Seurat objects. In Seurat v5, we keep all the data in one object, but simply split it into multiple ‘layers’. To learn more about layers, check out our Seurat object interaction vignette.

#### With default command from seurat data

```{r}
# devtools::install_github('satijalab/seurat-data')
InstallData("ifnb")
ifnb <- LoadData("ifnb")
```


```{r}
Assays(ifnb)
Layers(ifnb) # difference entre count et data ??

dim(ifnb)    # 14053 13999
table(ifnb$orig.ident)
table(ifnb$stim)
```

On splitte selon les deux conditions (counts.CTRL et counts.STIM)

```{r}
ifnb[["RNA"]] <- split(ifnb[["RNA"]], f = ifnb$stim)
ifnb

dim(ifnb[["RNA"]]$counts.CTRL)
dim(ifnb[["RNA"]]$counts.STIM)
```


#### Use count matrix as input instead of object


##### Method 1 from `?ifnb`

```bash
cd data/
wget https://www.dropbox.com/s/79q6dttg8yl20zg/immune_alignment_expression_matrices.zip
unzip immune_alignment_expression_matrices.zip
rm immune_alignment_expression_matrices.zip
```

```{r}
ctrl.data <- data.frame(data.table::fread('data/immune_control_expression_matrix.txt.gz',sep = "\t"),row.names=1)
stim.data <- data.frame(data.table::fread('data/immune_stimulated_expression_matrix.txt.gz',sep = "\t"),row.names=1)
ctrl <- Seurat::CreateSeuratObject(counts = ctrl.data, project = 'CTRL', min.cells = 5)
ctrl$stim <- 'CTRL'
ctrl <- subset(x = ctrl, subset = nFeature_RNA > 500)
stim <- Seurat::CreateSeuratObject(counts = stim.data, project = 'STIM', min.cells = 5)
stim$stim <- 'STIM'
stim <- subset(x = stim, subset = nFeature_RNA > 500)
ifnb <- merge(x = ctrl, y = stim)
Seurat::Project(object = ifnb) <- 'ifnb'
annotations <- readRDS(file = system.file('extdata/annotations/annotations.Rds', package = 'ifnb.SeuratData'))
ifnb <- Seurat::AddMetaData(object = ifnb, metadata = annotations)
```


```{r}
Assays(ifnb)
Layers(ifnb) # difference entre count et data ??

dim(ifnb)    # 14053 13999
table(ifnb$orig.ident)
table(ifnb$stim)
```

On splitte selon les deux conditions (counts.CTRL et counts.STIM)

```{r}
dim(ifnb[["RNA"]]$counts.CTRL)
dim(ifnb[["RNA"]]$counts.STIM)
```

##### Method 2 from GEO and using `Read10X`

From https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE96583

```bash
wget https://www.ncbi.nlm.nih.gov/geo/download/\?acc\=GSM2560248\&format\=file\&file\=GSM2560248%5F2%2E1%2Emtx%2Egz -O GSM2560248_2.1.mtx.gz
wget https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM2560248&format=file&file=GSM2560248%5Fbarcodes%2Etsv%2Egz -O GSM2560248_barcodes.tsv.gz
wget https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM2560249&format=file&file=GSM2560249%5F2%2E2%2Emtx%2Egz -O GSM2560249_2.2.mtx.gz
wget https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM2560249&format=file&file=GSM2560249%5Fbarcodes%2Etsv%2Egz -O GSM2560249_barcodes.tsv.gz

```

```r
expression_matrix_ctrl <- ReadMtx(
  mtx = "data/GSM2560248_2.1.mtx.gz", features = "data/GSE96583_batch2.genes.tsv.gz",
  cells = "data/GSM2560248_barcodes.tsv.gz"
)

ctrl <- Seurat::CreateSeuratObject(counts = expression_matrix_ctrl, project = 'CTRL', min.cells = 5)
ctrl$stim <- 'CTRL'
ctrl <- subset(x = ctrl, subset = nFeature_RNA > 500)

expression_matrix_stim <- ReadMtx(
  mtx = "data/GSM2560249_2.2.mtx.gz", features = "data/GSE96583_batch2.genes.tsv.gz",
  cells = "data/GSM2560249_barcodes.tsv.gz"
)

stim <- Seurat::CreateSeuratObject(counts = expression_matrix_stim, project = 'STIM', min.cells = 5)
stim$stim <- 'STIM'
stim <- subset(x = stim, subset = nFeature_RNA > 500)


ifnb <- merge(x = ctrl, y = stim)
Seurat::Project(object = ifnb) <- 'ifnb'

```

> **Warning** Issues with this method:
> Some cell names are duplicated across objects provided. Renaming to enforce unique cell names.

```r
table(colnames(ctrl[["RNA"]]) %in%colnames(stim[["RNA"]]))

FALSE  TRUE 
 7926   112 
```



### Normalization

- Fait la normalisation comme vu précédemment pour chaque matrice de counts 
(counts.CTRL --> data.CTRL et counts.STIM--> data.STIM)


```{r}
ifnb <- NormalizeData(ifnb)

ifnb@assays$RNA$data.CTRL[1:10,1:10]
ifnb@assays$RNA$data.STIM[1:10,1:10]
```

### HVG 

- HVG : il le fait pour chaque condition 

mais on a une répondre globale et un graphe global (pas par condition ?!)
  
```{r}
ifnb <- FindVariableFeatures(ifnb)

head(VariableFeatures(ifnb,assay="RNA",layer="counts.CTRL"))
head(VariableFeatures(ifnb,assay="RNA",layer="counts.STIM"))

top10<-head(VariableFeatures(ifnb), 10)
plot1<-VariableFeaturePlot(ifnb)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot2
```

### Dimension reduction sans integration

- En fait ça fait la réduction de dimension de toutes les données ensembles sans intégration ??

```{r}
ifnb <- ScaleData(ifnb)
ifnb <- RunPCA(ifnb)
ifnb <- FindNeighbors(ifnb, dims = 1:30, reduction = "pca")
ifnb <- RunUMAP(ifnb, dims = 1:30, reduction = "pca", reduction.name = "umap.unintegrated")
DimPlot(ifnb, reduction = "umap.unintegrated", group.by = c("stim"))
```

### Overview



### Integration dans Seurat




>We now aim to integrate data from the two conditions, so that cells from the same cell type/subpopulation will cluster together.

>We often refer to this procedure as intergration/alignment. When aligning two genome sequences together, identification of shared/homologous regions can help to interpret differences between the sequences as well. Similarly for scRNA-seq integration, our goal is not to remove biological differences across conditions, but to learn shared cell types/states in an initial step - specifically because that will enable us to compare control stimulated and control profiles for these individual cell types.

>The Seurat v5 integration procedure aims to return a single dimensional reduction that captures the shared sources of variance across multiple layers, so that cells in a similar biological state will cluster. The method returns a dimensional reduction (i.e. integrated.cca) which can be used for visualization and unsupervised clustering analysis. For evaluating performance, we can use cell type labels that are pre-loaded in the seurat_annotations metadata column.

- Seurat function: IntegrateLayers() 
- Five integration methods :

  + Anchor-based CCA integration (method=CCAIntegration)
  CCA = Canonical Correlation Analysis


  + Anchor-based RPCA integration (method=RPCAIntegration)
  + Harmony (method=HarmonyIntegration)
  + FastMNN (method= FastMNNIntegration)
  + scVI (method=scVIIntegration) --> Ne semble plus être dispo
  

https://www.biorxiv.org/content/10.1101/2024.12.16.628691v1.full.pdf 

  
### CCA

CCA = Canonical Correlation Analysis

>The goal of CCA here is to find linear combinations of the genes in both datasets that produce correlated cell embeddings in a lower-dimensional space. Essentially, we aim to align the two datasets by identifying the correlated patterns in gene expression that are shared between the two sets of cells.

> CCA c'est Dual PCA pour deux datasets. SVD $X Y^\top = U\Sigma V$ $Z_X = U \Sigma^{1/2}$ et $Z_Y = V \Sigma^{1/2}$
> $X$ et $Y$ deux jeux de données avec les mêmes gènes $X\in\mathbb R^{n\times g}$ et $Y\in\mathbb R^{m\times g}$
> find $a\in\mathbb R^g$ et $b\in\mathbb R^g$ such that $u=X^\top a$ et $v = Y^\top b$ where $u$ and $v$ are the canonical variates, and the goal is to maximize the correlation $\mbox{corr}(u,v)$. 
> Détail ici : https://divingintogeneticsandgenomics.com/post/cca-alignment/

![](images/CCA-DualPCA.png)

![](images/CCA-Seurat.png)

Explication: https://xinmingtu.cn/blog/2022/CCA_dual_PCA/


```{r}
ifnb_cca <- IntegrateLayers(object = ifnb, 
                        method = CCAIntegration, 
                        orig.reduction = "pca", 
                        new.reduction = "integrated.cca",
                        verbose = FALSE)
# re-join layers after integration
ifnb_cca[["RNA"]] <- JoinLayers(ifnb_cca[["RNA"]])
# Dimension reduction
ifnb_cca <- FindNeighbors(ifnb_cca, 
                      reduction = "integrated.cca", 
                      dims = 1:30)
ifnb_cca <- RunUMAP(ifnb_cca, 
                dims = 1:30, 
                reduction = "integrated.cca")
```

```{r}
p1<-DimPlot(ifnb, reduction = "umap.unintegrated", group.by = c("stim"))
p2<-DimPlot(ifnb_cca, reduction = "umap", group.by = c("stim"))
p1+p2
```


### Harmony

> The Harmony algorithm inputs a PCA embedding (Z) of cells, along with their batch assignments (ϕ), and returns a batch corrected embedding (). This algorithm, summarized as Algorithm 1 below, iterates between two complementary stages: maximum diversity clustering (Algorithm 2) and a mixture model based linear batch correction (Algorithm 3). The clustering step uses the batch corrected embedding to compute a soft assignment of cells to clusters, encoded in the matrix R. The correction step uses these soft clusters to compute a new corrected embedding from the original one. Efficient implementations of Harmony, including the clustering and correction subroutines, are available as part of an R package at https://github.com/immunogenomics/harmony.

![](images/HarmonyAlgo1.png)
![](images/HarmonyAlgo2.png)
![](images/HarmonyAlgo3.png)




![](images/HarmonyIntegration.png)  


```{r}
ifnb_h <- IntegrateLayers(object = ifnb, 
                        method = HarmonyIntegration, 
                        orig.reduction = "pca", 
                        new.reduction = "integrated.harmony",
                        verbose = FALSE)
# re-join layers after integration
ifnb_h[["RNA"]] <- JoinLayers(ifnb_h[["RNA"]])
# Dimension reduction
ifnb_h <- FindNeighbors(ifnb_h, 
                      reduction = "integrated.harmony", 
                      dims = 1:30)
ifnb_h <- RunUMAP(ifnb_h, 
                dims = 1:30, 
                reduction = "integrated.harmony")
```

```{r}
p3<-DimPlot(ifnb_h, reduction = "umap", group.by = c("stim"))
p1+p2+p3
```

  
### Clustering 

Pour la suite, on poursuit avec l'intégration par CCA

```{r}
ifnb<-ifnb_cca

ifnb <- FindClusters(ifnb, resolution = 0.5)

# Visualization
DimPlot(ifnb, 
        reduction = "umap", 
        group.by = c("stim", "seurat_clusters"))

DimPlot(ifnb, reduction = "umap", split.by = "stim")
```


```{r}
Aux<-melt(table(Idents(ifnb),ifnb$stim))
colnames(Aux)<-c("Cluster","Condition","len")
ggplot(data=Aux, aes(x=Cluster, y=len, fill=Condition)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=len), vjust=1.6, color="white",
            position = position_dodge(0.9), size=3.5)+
  theme_minimal()
```

### Annotations

- annotation Seurat des données est disponible

```{r}
Idents(ifnb)<- "seurat_annotations"
table(Idents(ifnb))

DimPlot(ifnb, 
        reduction = "umap", 
        group.by = c("seurat_annotations"))
```




### Identify conserved cell type markers

> To identify canonical cell type marker genes that are conserved across conditions, we provide the FindConservedMarkers() function. This function performs differential gene expression testing for each dataset/group and combines the p-values using meta-analysis methods from the MetaDE R package. For example, we can calculated the genes that are conserved markers irrespective of stimulation condition in cluster 6 (NK cells).

```{r}
Idents(ifnb) <- "seurat_annotations"
NK.markers <- FindConservedMarkers(ifnb, 
                                   ident.1 = "NK", 
                                   grouping.var = "stim", 
                                   verbose = FALSE)
head(NK.markers)
```

calcul FindMarkers pour la classe "NK" contre les autres seulement pour les cellules de STIM et celles de CTRL. 
Puis, combine les pvaleurs selon une fonction du package metap. 
(Fishers combined p-value or others from the metap package)).
Par défaut dans la fonction FindConservedMarkers, meta.method = metap::minimump ---> Wilkinson's method 
(wilkinsonp(p, r = 1, alpha, log.p))

ref pour les méthodes de combinaison de pvaleurs
https://cran.r-project.org/web/packages/metap/vignettes/compare.pdf


```{r}
NK.markers<-NK.markers%>%
  arrange(minimump_p_val)

DotPlot(ifnb, features = rownames(NK.markers)[1:10], 
        cols = c("blue", "red"), dot.scale = 8, split.by = "stim") +
    RotatedAxis()
```

### Differential analysis

#### Attention !

- Il faut bien avoir en tête son design
- Il faut bien réfléchir à la question à laquelle on souhaite répondre
- Bcp de méthodes proposées mais 


#### DOC

https://pmc.ncbi.nlm.nih.gov/articles/PMC9315519/ : table avec bcp de méthodes

![](images/Nguyenetal-NatureComm2023.png)

https://academic.oup.com/bfg/article/23/2/95/7107938

![](images/Dasetal-Entropy22-ReviewDEA.png)



### Example

D'abord ajout d'informations pour avoir des "replicats"

```{r}
# load the inferred sample IDs of each cell
ctrl <- read.table(url("https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye1.ctrl.8.10.sm.best"), head = T, stringsAsFactors = F)
stim <- read.table(url("https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye2.stim.8.10.sm.best"), head = T, stringsAsFactors = F)
info <- rbind(ctrl, stim)

# rename the cell IDs by substituting the '-' into '.'
info$BARCODE <- gsub(pattern = "\\-", replacement = "\\.", info$BARCODE)

# only keep the cells with high-confidence sample ID
info <- info[grep(pattern = "SNG", x = info$BEST), ]

# remove cells with duplicated IDs in both ctrl and stim groups
info <- info[!duplicated(info$BARCODE) & !duplicated(info$BARCODE, fromLast = T), ]

# now add the sample IDs to ifnb 
rownames(info) <- info$BARCODE
info <- info[, c("BEST"), drop = F]
names(info) <- c("donor_id")
ifnb <- AddMetaData(ifnb, metadata = info)

# remove cells without donor IDs
ifnb$donor_id[is.na(ifnb$donor_id)] <- "unknown"
ifnb <- subset(ifnb, subset = donor_id != "unknown")
```

```{r}
table(ifnb$donor_id)
```

Pour la suite, création d'une colonne Condition_TypeCellulaire

```{r}
ifnb$celltype.stim <- paste(ifnb$seurat_annotations, ifnb$stim, sep = "_")
table(ifnb$celltype.stim)
```



#### Question 1

Question 1:  déterminer les gènes dont l'expression varie entre les deux conditions (types cellulaires confondus)


##### Par méthode naive (Wilcoxon)

```{r}
Idents(ifnb)<-ifnb$stim
res1_Wilcox <- FindMarkers(object = ifnb, 
                           ident.1 = "STIM", 
                           ident.2 = "CTRL",
                           test.use = "wilcox")

mean(res1_Wilcox$p_val_adj<0.01)

genetop_wilcox1<-res1_Wilcox %>%
   filter(p_val_adj<0.01)%>%
   arrange(desc(abs(avg_log2FC)))%>%
   top_n(100)
```

```{r}
DotPlot(ifnb,features=rownames(genetop_wilcox1)[1:10],group.by="stim")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


##### Par pseudo-bulk (DESeq2)

```{r}
# Question 1 : on regroupe par conditions et donor_id pour la création du pseudoBulk
pseudo_ifnb1 <- AggregateExpression(ifnb, 
                                   assays = "RNA", 
                                   return.seurat = T, 
                                   group.by = c("stim", "donor_id"))

head(pseudo_ifnb1)
```

```{r}
# DESeq2 depuis Seurat
Idents(pseudo_ifnb1)<-"stim"
bulk.cond1 <- FindMarkers(object = pseudo_ifnb1, 
                         ident.1 = "STIM", 
                         ident.2 = "CTRL",
                         test.use = "DESeq2")
```


```{r}
# En passant par le package DESeq2
library(DESeq2)
cts1<-as.matrix(pseudo_ifnb1@assays$RNA$counts)
coldata1<-pseudo_ifnb1@meta.data
dds1 <- DESeqDataSetFromMatrix(countData = cts1,
                              colData = coldata1,
                              design= ~ donor_id + stim) 
dds1 <- DESeq(dds1,fitType = c("local"))                      
resultsNames(dds1) # lists the coefficients

resDEseq1<-results(dds1,name="stim_STIM_vs_CTRL")
length(which(resDEseq1$padj<0.01)) / nrow(resDEseq1)
```

```{r}
genetopDEseq1<-as.data.frame(resDEseq1) %>%
   filter(padj<0.01)%>%
   arrange(desc(abs(log2FoldChange)))%>%
   top_n(200)
```

```{r}
DotPlot(ifnb,features=rownames(genetopDEseq1)[1:10],group.by="stim")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


library(pheatmap)
pheatmap(pseudo_ifnb1@assays$RNA$scale.data[rownames(genetopDEseq1),],
         cluster_cols = FALSE,       
         scale = "column",              
         show_rownames = FALSE,
         show_colnames = TRUE)
```


##### Par une méthode spécifique single-cell (ex: NEBULA)

Pour la question 1 :

```{r}
library(nebula)
ifnb_neb1<-scToNeb(obj=ifnb,assay="RNA",id="donor_id",pred=c("stim","seurat_annotations"))
df1 = model.matrix(~stim+seurat_annotations, data=ifnb_neb1$pred)
data_g = group_cell(count=ifnb_neb1$count,id=ifnb_neb1$id,pred=df1) # il faut grouper les cellules par indiv avant de faire nebula
re1 = nebula(data_g$count,data_g$id,pred=data_g$pred)

mean(p.adjust(re1$summary$p_stimSTIM,method="BH")<0.01)

ifnbNebSumm1<-re1$summary
ifnbNebSumm1$padjStim<-p.adjust(re1$summary$p_stimSTIM,method="BH")
ifnbNebSumm1<-ifnbNebSumm1%>%
            filter(padjStim <0.01)%>%
            arrange(desc(abs(logFC_stimSTIM)))  
head(ifnbNebSumm1)
```

```{r}
genetopNeb1<-ifnbNebSumm1%>%
   top_n(200)

DotPlot(ifnb,features=genetopNeb1$gene[1:30],group.by="stim")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

pheatmap(pseudo_ifnb1@assays$RNA$scale.data[genetopNeb1$gene,],
         cluster_cols = FALSE,       
         scale = "column",              
         show_rownames = FALSE,
         show_colnames = TRUE)
```

##### Comparaison

```{r}
library(ggvenn)
ggvenn(list(DEseq2=rownames(genetopDEseq1),Nebula=genetopNeb1$gene,Wilcox=rownames(genetop_wilcox1)))
```


#### Question 2

Question 2 : déterminer les gènes dont l'expression varie entre les deux conditions pour le type cellulaire "CD14 Mono" fixé.


```{r}
# Question 2
ICD14Mono<-which(ifnb$seurat_annotations=="CD14 Mono")

Idents(ifnb)<-ifnb$celltype.stim
res2_Wilcox <- FindMarkers(object = ifnb, 
                           ident.1 = "CD14 Mono_STIM", 
                           ident.2 = "CD14 Mono_CTRL",
                           test.use = "wilcox")

mean(res2_Wilcox$p_val_adj<0.01)

genetop_wilcox2<-res2_Wilcox %>%
   filter(p_val_adj<0.01)%>%
   arrange(desc(abs(avg_log2FC)))%>%
   top_n(100)
```

```{r}
DotPlot(ifnb[,ICD14Mono],features=rownames(genetop_wilcox2)[1:10],group.by="stim")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}
# pseudobulk
pseudo_ifnb2 <- AggregateExpression(ifnb[,ICD14Mono], 
                                   assays = "RNA", 
                                   return.seurat = T, 
                                   group.by = c("stim", "donor_id", "seurat_annotations"))

cts2<-as.matrix(pseudo_ifnb2@assays$RNA$counts)
coldata2<-pseudo_ifnb2@meta.data
dds2 <- DESeqDataSetFromMatrix(countData = cts2,
                              colData = coldata2,
                              design= ~ donor_id + stim) 
dds2 <- DESeq(dds2,fitType = c("local"))                      
resultsNames(dds2) # lists the coefficients

resDEseq2<-results(dds2,name="stim_STIM_vs_CTRL")
length(which(resDEseq2$padj<0.01)) / nrow(resDEseq2)
```


```{r}
genetopDEseq2<-as.data.frame(resDEseq2) %>%
   filter(padj<0.01)%>%
   arrange(desc(abs(log2FoldChange)))%>%
   top_n(100)

DotPlot(pseudo_ifnb2,features=rownames(genetopDEseq2)[1:10],group.by="stim")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

pheatmap(pseudo_ifnb2@assays$RNA$scale.data[rownames(genetopDEseq2),],
         cluster_cols = FALSE,       
         scale = "column",              
         show_rownames = FALSE,
         show_colnames = TRUE)
```



```{r}
# Nebula
Idents(ifnb)<-ifnb$seurat_annotations
ifnb_neb2<-scToNeb(obj=ifnb[,ICD14Mono],assay="RNA",id="donor_id",pred=c("stim"))
df2 = model.matrix(~stim, data=ifnb_neb2$pred)
data_g2 = group_cell(count=ifnb_neb2$count,id=ifnb_neb2$id,pred=df2) # il faut grouper les cellules par indiv avant de faire nebula
re2 = nebula(data_g2$count,data_g2$id,pred=data_g2$pred)

mean(p.adjust(re2$summary$p_stimSTIM,method="BH")<0.01)

ifnbNebSumm2<-re2$summary
ifnbNebSumm2$padjStim<-p.adjust(re2$summary$p_stimSTIM,method="BH")
ifnbNebSumm2<-ifnbNebSumm2%>%
            filter(padjStim <0.01)%>%
            arrange(desc(abs(logFC_stimSTIM)))  
head(ifnbNebSumm2)
```

```{r}
genetopNeb2<-ifnbNebSumm2%>%
   top_n(100)

DotPlot(ifnb,features=genetopNeb2$gene[1:10],group.by="stim")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


library(pheatmap)
pheatmap(pseudo_ifnb2@assays$RNA$scale.data[genetopNeb2$gene,],
         cluster_cols = FALSE,       
         scale = "row",              
         show_rownames = FALSE,
         show_colnames = TRUE)
```




##### Par une approche supervisée (ex: Random Forest)


```{r}
library(randomForest)
library(caret)

#SeuratObject@meta.data$TreatGenotype<-paste0(SeuratObject$Treatment,"-",SeuratObject$Genotype)
#IBanq1<-which(SeuratObject@meta.data$Banque=="Bq1")


datatrain<-t(as.matrix(ifnb@assays$RNA$scale.data[,ICD14Mono]))
dataRF<-data.frame(datatrain,
                   Cl = as.factor(ifnb$stim[ICD14Mono]))
resRF<-randomForest(Cl ~ ., data = dataRF,importance=T,proximity=T)
varImpPlot(resRF)
table(resRF$predicted,dataRF$Cl)


genetopRF2<-as.data.frame(resRF$importance)%>%
      arrange(desc(MeanDecreaseAccuracy))%>%
      top_n(100)
```

```{r}
DotPlot(ifnb,features=rownames(genetopRF2)[1:10],group.by="stim")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


#library(pheatmap)
#pheatmap(pseudo_ifnb2@assays$RNA$scale.data[rownames(genetopRF2),],
#         cluster_cols = FALSE,       
#         scale = "row",              
#         show_rownames = FALSE,
#         show_colnames = TRUE)
```

##### Comparaison

```{r}
library(ggvenn)
ggvenn(list(DEseq2=rownames(genetopDEseq2),Nebula=genetopNeb2$gene,Wilcox=rownames(genetop_wilcox2),RF=rownames(genetopRF2)))
```

## Gene functional analysis


Gene enrichment analysis identifies __biological pathways__ or __functions__ that are __overrepresented__ in a set of genes of interest.

In functional analysis of biological pathway, the biologist is __always__ the expert :

* The pathway database is determinent.
* You decide the relationship and biological significance of the data you want to present.



### Why ?

The interpretation of the list of differentially expressed genes can be challenging due to two scenarios:

1.  The list is so long that it becomes cumbersome and time-consuming to analyze and interpret each gene individually.

2.  Some genes may have low p-values but not low enough to meet the given threshold for significance.


**In such situations, enrichment analysis can be employed to enhance the understanding of our dataset.**


### Approaches



1.  **Over Representation Analysis (ORA)**: This method determines whether the differentially expressed genes are enriched in specific pathways or ontological groups. It assesses whether the observed number of genes in a particular pathway or gene ontology term is higher than what would be expected by chance.

2.  **Gene Set Enrichment Analysis (GSEA)**: GSEA evaluates whether a pre-defined set of genes (gene set) shows statistically significant differences between two or more biological conditions. Instead of focusing on individual genes, GSEA considers the collective behavior of genes within a gene set to identify enriched biological pathways or functional categories.
  


### From (Gene) Symbols to (Gene) IDs

Working with gene IDs, such as `Ensembl IDs`, instead of gene symbols is important for reproducibility in gene enrichment analysis due to the following reasons:

1.  **Gene Symbol Ambiguity:** Gene symbols can be ambiguous, as multiple genes can have the same symbol. This can lead to confusion and errors when performing analyses, especially when using external databases or tools.

2.  **Uniqueness:** Gene IDs are unique identifiers assigned to specific genes. They provide a standardized and consistent way of referring to genes across different datasets and analyses, ensuring accuracy and reproducibility.

3.  **Consistent Annotation:** Gene IDs are linked to comprehensive and up-to-date gene annotation databases, such as Ensembl. These databases provide detailed information about gene features, genomic locations, functional annotations, and other relevant metadata.

4.  **Cross-Species Comparisons:** Gene IDs enable seamless comparisons of gene enrichment results across different species.

5.  **Data Integration:** Gene IDs facilitate data integration across multiple experiments or studies. They enable the merging of different datasets, such as gene expression data or functional annotations, based on a common identifier.

6.  **Long-term Accessibility:** Gene IDs are stable and persist over time.

Using Gene IDs: enhances reproducibility in gene enrichment analysis by providing unique and standardized gene identifiers, enabling consistent annotation, supporting cross-species comparisons, facilitating data integration, and ensuring long-term accessibility of results.

### `bitr`: Biological Id TranslatoR

```{r}
eg = bitr(rownames(genetop_wilcox1), fromType="SYMBOL", toType="ENTREZID", OrgDb="org.Hs.eg.db")
eg  |> as_tibble()  |>  rmarkdown::paged_table()
```

### Ensembl BioMart

BioMart provides a flexible and intuitive interface to explore and retrieve genomic data from Ensembl. It allows you to filter and select specific data attributes, enabling you to extract the information that is most relevant to your research or analysis.

1.  **Accessing BioMart**: Go to the Ensembl website (<https://www.ensembl.org>) and click on the "BioMart" option in the menu to access the BioMart interface.

2.  **Choosing a Dataset**: In the BioMart interface, you will see several tabs. Start by selecting the "CHOOSE DATABASE" tab. Here, you can choose the dataset you want to retrieve data from, such as the Ensembl genes, variation, or sequence databases.

3.  **Selecting Filters**: Once you've chosen the dataset, click on the "CHOOSE FILTERS" tab. Here, you can specify criteria to filter the data you are interested in. For example, you can filter by gene ID, chromosome location, gene biotype, or other attributes.

4.  **Selecting Attributes**: After setting your filters, switch to the "CHOOSE ATTRIBUTES" tab. Here, you can select the specific attributes or data fields you want to retrieve for the filtered data. These attributes can include gene names, chromosomal coordinates, functional annotations, or any other available information.

5.  **Retrieving Results**: Once you have chosen the desired attributes, switch to the "RESULTS" tab. Click on the "Results" button to retrieve the data based on your chosen filters and attributes. The results will be displayed in a table format.


Ensembl Biomart have an R api called `bioMart`:
```{r}
require(biomaRt)
listMarts()
```
```{r}
mart <- biomaRt::useMart(biomart="ENSEMBL_MART_ENSEMBL")
listEnsembl(mart=mart)
```

Check datasets availables

```{r,echo=T}
ensembl <- useEnsembl(biomart = "ensembl",version =114)
datasets <- listDatasets(ensembl)
datasets %>% as_tibble() %>% rmarkdown::paged_table()
```



### Now we can ask for the same thing but with `R` :

```{r}
ensembl <- useDataset(dataset = "hsapiens_gene_ensembl", mart = ensembl)
```

### If the dataset is known in advance:

```{r,eval=F}
ensembl <- useEnsembl(biomart = "ensembl", dataset = "hsapiens_gene_ensembl",version =114)
```


### Query in `biomaRt`

The `getBM()` function is the primary query function in biomaRt.

It has four main arguments:

-   `attributes`: is a vector of attributes that one wants to retrieve (= the output of the query).
-   `filters`: is a vector of filters that one wil use as input to the query.
-   `values`: a vector of values for the filters. In case multple filters are in use, the values argument requires a list of values where each position in the list corresponds to the position of the filters in the filters argument (see examples below).
-   `mart`: is an object of class Mart, which is created by the useEnsembl() function.


```{r}
filters = listFilters(ensembl)
filters  %>% as_tibble() %>% rmarkdown::paged_table()
```

```{r}
attributes = listAttributes(ensembl)
attributes %>% as_tibble() %>% rmarkdown::paged_table()
```


```{r}

gene_conversion <- getBM(attributes = c("ensembl_gene_id","entrezgene_id","hgnc_symbol"),
      filters = "hgnc_symbol",
      values = rownames(genetop_wilcox1), 
      mart = ensembl)
gene_conversion %>% as_tibble() %>% rmarkdown::paged_table()
```

### AnnotationHub

#### Get proper annotation for `AnnotationHub` using `BiocHubsShiny`:

The `BiocHubsShiny` package allows users to visually explore the `AnnotationHub` and `ExperimentHub` resources via shiny. It provides a tabular display of the available resources with the ability to filter and search through the column fields.[^1]

[^1]: From `BiocHubsShiny` vignette : https://bioconductor.org/packages/release/bioc/vignettes/BiocHubsShiny/inst/doc/BiocHubsShiny.html

```{r,eval=FALSE,echo=T}
BiocHubsShiny::BiocHubsShiny()

library("AnnotationHub")
hub <- AnnotationHub()

## Select rows in the table

ens.db <- hub[['AH119325']]
```

Query ens.db

```{r,eval=FALSE,}
select(ens.db, keys=rownames(genetop_wilcox1),columns=c("SYMBOL", "GENEID","ENTREZID","GENENAME","GENEBIOTYPE"),keytype = "GENENAME")
```


### Common sources of feature sets

1. **Gene Ontology (GO)**
2. **KEGG (Kyoto Encyclopedia of Genes and Genomes)**:
3. **WikiPathways**
4. **Disease Ontology**
5. **Reactome**
6. **Molecular Signatures Database (MSigDB)**
7. **Medical Subject Headings (MeSH)**

These pathway collections databases serve as valuable resources for researchers to explore and analyze biological pathways, functional annotations, and disease associations. They facilitate the interpretation of gene expression data, identify key pathways related to specific biological processes or diseases, and contribute to a deeper understanding of biological systems.


### **Gene Ontology (GO)**

::: {style="font-size: 18px;"}

### Website: <http://geneontology.org/>

### Description: 
GO is a widely used database that categorizes genes into three main ontologies: molecular function, biological process, and cellular component. It provides a standardized vocabulary to describe gene functions and interactions, allowing researchers to annotate and analyze gene sets in a structured manner.


1. **Molecular Function**
   - Describes the elemental activities of a gene product at the molecular level.
2. **Biological Process**
   - Represents sets of molecular events or biological pathways achieved by one or more gene products.
   - Biological process terms describe the larger, coordinated series of events that involve multiple molecular functions.
3. **Cellular Component**
   - Refers to the subcellular structures, locations, and macromolecular complexes in which gene products are active.
   - Cellular component terms describe the physical compartments or structures where gene products function.


:::{.callout-tip}
* [Ten Quick Tips for Using the Gene Ontology](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003343)
:::

:::



### Over Representation analysis

Over Representation Analysis (ORA) is a widely used approach to determine whether known biological functions or processes are over-represented (= enriched) in an experimentally-derived gene list, e.g. a list of differentially expressed genes (DEGs).

![From bioinformatics-core-shared-training.github.io/Bulk_RNAseq_Course_Apr22](images/genesetoverlap.svg){fig-align="center"}

### Over Representation analysis

![From bioinformatics-core-shared-training.github.io/Bulk_RNAseq_Course_Apr22](images/contingency.png){fig-align="center" width="400" height="300"}

### Fisher Exact Test

-   The Fisher Exact Test is a statistical method used to determine whether there is a significant association between two categorical variables, such as the presence or absence of a particular gene and a particular phenotype or disease.
-   In the context of gene enrichment analysis, the Fisher Exact Test is used to determine whether there is a significant association between a set of genes and a particular biological pathway or process.

Hypothesis: 

* $H_0$: The categories are independent.
* $H_1$: The categories are dependent.

> In Gene Enrichment, we want to see as genes as possible in the pathway that are DE, so we want a one sided test with greater hypothesis.




### Fisher Exact Test

The p-value can be calculated by hypergeometric distribution[^1]: 

$$
p = 1 - \displaystyle\sum_{i = 0}^{k-1}\frac{{M \choose i}{{N-M} \choose {n-i}}} {{N \choose n}}
$$

* $N$ is the total number of genes in the background distribution
* $M$ is the number of genes within that distribution that are annotated (either directly or indirectly) to the gene set of interest
* $n$ is the size of the list of genes of interest
* $k$ is the number of genes within that list which are annotated to the gene set. 

![From Wieder et al. (https://doi.org/10.1371/journal.pcbi.1009105)](images/ora.PNG){fig-align="center" width="250" height="250"}


[^1]: In case of alternative hypothesis as `greater`.

### Fisher Exact Test

#### With an (false) example

![From https://www.pathwaycommons.org/guide/primers/statistics/fishers_exact_test/](images/table_1.png){fig-align="center" width="400" height="300"}

### Fisher Exact Test

#### With an (false) example

![From https://www.pathwaycommons.org/guide/primers/statistics/fishers_exact_test/](images/figure_1.png){fig-align="center"}



### Fisher Exact Test

#### With an (false) example

![From https://www.pathwaycommons.org/guide/primers/statistics/fishers_exact_test/](images/table_2.png){fig-align="center" width="400" height="300"}

### Fisher Exact Test

#### Using the Hypergeometric distribution

$$
\begin{equation*}
  \begin{split}
    \frac{(\text{15 Choose 1})\cdot(\text{15 Choose 14})}{(\text{30 Choose 15})}& = \frac{15\cdot15}{155 117 520}\\
    & = 1.45\cdot10^{-6}
  \end{split}
\end{equation*}
$$

### Fisher Exact Test

#### With an (false) example

![From https://www.pathwaycommons.org/guide/primers/statistics/fishers_exact_test/](images/figure_3.png){fig-align="center"}



### Fisher Exact Test

#### Solution

$$
\begin{equation*}
  \begin{split}
    p& = \sum\limits_{\text{DE & IN}\geq12}p_i\\
     & = 1.33\cdot10^{-3}+7.11\cdot10^{-5}+1.45\cdot10^{-6}+6.45\cdot10^{-9}\\
     & = 0.001407159\\
     & \simeq 0.0014
  \end{split}
\end{equation*}
$$

### Fisher Exact Test

#### With a real dataset 



```{r, warning=FALSE,message=FALSE}
require(clusterProfiler)
require(gt)
require(org.Hs.eg.db)
# eg = bitr(rownames(genetop_wilcox1), fromType="SYMBOL", toType="ENTREZID", OrgDb="org.Hs.eg.db")
# go_enrichment <- enrichGO(eg$ENTREZID, OrgDb = org.Hs.eg.db::org.Hs.eg.db, keyType = "ENTREZID", ont = "BP")
# saveRDS(go_enrichment,"data/go_enrichment.rds")
go_enrichment <- readRDS("data/go_enrichment.rds")
go_enrichment <- setReadable(go_enrichment, OrgDb = org.Hs.eg.db, keyType="ENSEMBL")
my_go <- "GO:0071901"
my_go <- go_enrichment %>% as_tibble() %>% arrange(desc(p.adjust)) %>% dplyr::filter(ID == my_go)

k = 5
M = 86 
N = 18986
n = 83


d <- data.frame(gene.in.interest=c(k,n-k),gene.not.interest=c(M-k,N-M-n+k))
row.names(d) <- c("In_category", "not_in_category")

mytable <- d
mytable <- rbind(mytable,colSums(d))
mytable <- cbind(mytable,rowSums(mytable))
colnames(mytable) <- c("Of_interest_yes", "Of_interest_no","Total")
rownames(mytable) <- c("in_pathway_yes","in_pathway_no","Total")

desired_colnames <- colnames(mytable) |> 
  str_remove('Of_interest_') |> 
  str_to_title()
names(desired_colnames) <- colnames(mytable)


options(scipen=999)

```

For a gene set `r my_go$Description` (`r my_go$ID`), I have :

* `r N` ($N$) number of genes in the analysis (background distribution).
* `r M` ($M$) genes within that distribution that are in the pathway of interest $C$.
* `r n` ($n$) genes of interest ($S$).
* `r k` ($k$) genes that are in $S$ and $C$.

And we can draw this contingency table:

```{r echo=FALSE, warning=FALSE,message=FALSE}
options(scipen=0)
mytable %>% tibble::rownames_to_column("Pathway") %>% mutate(Pathway = glue::glue("**Pathway of interest**: {str_extract(Pathway,'yes|no|Total')}")) %>%  gt(rowname_col = "Pathway") %>% cols_label(.list = desired_colnames) |> 
  tab_spanner(
    label = md('**Genes of interest**'),
    columns = 1:2
  ) %>%  fmt_markdown(columns = everything()) %>% 
  tab_header(
    title = glue::glue("Contingency table: DE genes against {my_go$Description} ({my_go$ID})")
  )
```




### Tests with `R`

#### Using Hypergeometric distribution


```{r}
all_probas <- dhyper(0:M, M, N-M, n,log=F)
```


```{r,echo=F}
p1 <- enframe(all_probas) %>% ggplot(aes(x=name,y=value)) + geom_line() + labs(y="probability",x="k",title = "Probability of observing our table giving k") + geom_vline(xintercept = 5,linetype='dashed',col="red")
print(p1)
```


### Tests with `R`

#### Using Hypergeometric distribution
#### Summing all probability having $k=32$ or more : 
```{r}
dhyper(k:M, M, N-M, n,log=F) %>% sum()
```


#### Using the distribution function directly

```{r}
phyper(k-1, M, N-M, n,lower.tail =F)
```


Or even if we want to replicate the formula :

```{r}
1-phyper(k-1, M, N-M, n)
```

### Using Fisher Test directly

```{r}
fisher.test(d, alternative = "greater")
```




### Over Representation Test tools

#### Online tools

* PANTHER (<http://geneontology.org/> or <http://www.pantherdb.org/>)
* gprofiler (<https://biit.cs.ut.ee/gprofiler/gost>)
* DAVID (<https://david.ncifcrf.gov/>)
* WEB-based GEne SeT AnaLysis Toolkit (WebGestalt) <https://www.webgestalt.org/>

#### Programmatic (R) tools 

* `ClusterProfiler`
* `hypeR`
* `gprofiler2`
* `rbioapi`: R api to query Enrichr, miEAA, PANTHER, Reactome, and STRING.

### `clusterProfiler`



#### And a `orgDB` object

```{r,eval=FALSE}
#| message: false
#| warning: false

require(clusterProfiler)
require(org.Hs.eg.db)
org.db <- org.Hs.eg.db

## We can also use our own DB
hub <- AnnotationHub()
org.db <- hub[['AH111575']]
org.db


```



#### GO over-representation analysis

The clusterProfiler package implements `enrichGO()` for gene ontology over-representation test.


```{r}
#| message: false
#| warning: false
org.db <- org.Hs.eg.db::org.Hs.eg.db
gene  rownames(genetop_wilcox1)
ego <- enrichGO(gene          = eg$ENTREZID,
                universe      = NULL,
                OrgDb         = org.db,
                keyType = "ENTREZID",
                ont           = "BP",
                pAdjustMethod = "BH",
                pvalueCutoff  = 0.01,
                qvalueCutoff  = 0.05,
                readable      = TRUE)

ego %>% as_tibble()
```


#### Basic visualisations: Dotplot

```{r}
#| echo: false

dotplot(ego,showCategory=10)
```

# Pour aller plus loin

## Spatial transcriptomic (ST)

### ST Data

- The **spot** by gene expression matrix 

- The information necessary to associate spots with their physical position on the tissue image


![](images/SpatialTransc.png)

### Example

Description: 

- Mouse brain spatial expression for the anterior region

$G=31053$ genes across $C=2696$ spots 

```{r}
InstallData("stxBrain")
brain <- LoadData("stxBrain", type = "anterior1")
brain
```

Contenu de l'objet : 

![](images/Object-ST-1.png)

```{r}
brain@assays$Spatial$counts[1:6,1:10]
brain@images$anterior1
```

```{r}
SpatialFeaturePlot(brain, features = "nCount_Spatial") + 
  theme(legend.position = "right")
```

### Pipeline

- Normalization

- Dimension reduction

- **Clustering** : take into account spatial information

- Marker genes 

- ....

- Detecting **spatially-variable features**

### Normalization

- Variance in molecular counts across spots is not just technical in nature, but also is dependent on the tissue anatomy. Standard approaches (such as the `LogNormalize()` function), which force each data point to have the same underlying ‘size’ after normalization, can be problematic.

- Recommend using sctransform (Hafemeister and Satija, Genome Biology 2019)

regularized negative binomial models of gene expression in order to account for technical artifacts while preserving biological variance. 
UMI counts across cells in a dataset are modeled using a generalized linear model (GLM). The total UMI count per cell is used as an offset in the GLM. 

$$
x_{gc}\sim\mbox{NB}(\mu_{gc},\theta_g) \hspace{0.5cm} \ln(\mu_{gc})= \beta_{0g}+\ln(n_c)
$$
with $n_c = \sum_g x_{gc}$. 
We perform three steps to remove technical noise and perform variance stabilization:

  - Step 1: the inverse overdispersion parameter $\theta$ is individually estimated using a subset of genes (2000 by default), which are sampled in a density-dependent manner according to their average abundance. 
  Step 2:  we calculate a smoothed curve that characterizes the global relationship between $\mu$ and $\theta$, thereby regularizing $\theta$ estimates as a function of gene mean. We perform the same regularization for the intercept parameter. We use the geometric mean to estimate gene abundance, which is more robust to outlier values in scRNA-seq. As outlier values can originate from multiple sources including the presence of cell doublets, errors in UMI collapsing, or ambient RNA, we have empirically improved performance when using the geometric mean instead of the arithmetic mean. Although sctransform supports multiple estimators for $\theta$, we recommend the use
of glmGamPoi, an alternate estimator that is more robust and faster.

  - Step 3: we use the regularized parameter estimates to calculate Pearson
residuals $Z_{gc}$. The “residual variance” for a gene represents the remaining variation in gene expression that is not explained by the sctransform model,

- `sctransform` normalizes the data, detects high-variance features, and stores the data in the SCT assay.

![](images/Object-ST-2.png)


```{r}
#Normalization
brain <- SCTransform(brain, assay = "Spatial", verbose = FALSE)
brain@assays$SCT

##-> englobe etape de normalisation, HVG, scale data
VariableFeaturePlot(brain)

SpatialFeaturePlot(brain, features = c("Ttr","Hbb-bs"))
```

### Dimension reduction

```{r}
#Dimension reduction
brain <- RunPCA(brain, assay = "SCT", verbose = FALSE)
brain <- FindNeighbors(brain, reduction = "pca", dims = 1:30)
brain <- RunUMAP(brain, reduction = "pca", dims = 1:30)
DimPlot(brain, reduction = "umap")+NoLegend()
```


![](images/Object-ST-3.png)



### Clustering 

![](images/Cheng-BriefInform2023.png)

![](images/Xiongetal-bioRxiv2025.png)

Exemple avec BayesSpace

```{r}
library(BayesSpace)
diet.seurat = Seurat::DietSeurat(brain,
                                   graphs = "SCT_nn",
                                   dimreducs = c("pca"))
sce_brain = as.SingleCellExperiment(diet.seurat, assay = "SCT") 
colData(sce_brain) = cbind(colData(sce_brain),
                           brain@images$anterior1$centroids@coords) 
sce_brain$array_col<-sce_brain$y 
sce_brain$array_row<-sce_brain$x 

sce_brain = spatialPreprocess(sce_brain, 
                          platform = "Visium",
                          skip.PCA = T, 
                          log.normalize = log.normalize) 
sce_brain <- spatialCluster(sce_brain,
                          nrep = 1000,
                          q= 8,
                          burn.in = 10,
                          model = "t",
                          gamma = 2)
brain@meta.data[["BayesSpace"]] <- as.factor(sce_brain$spatial.cluster)
```

```{r}
table(brain$BayesSpace) # mettre plutot le graphe

p1<-SpatialDimPlot(brain, "BayesSpace",label=TRUE,label.size=2)

p2<-DimPlot(brain, reduction = "umap",group.by="BayesSpace",label=TRUE)
p1+p2
```

Fonctions interaction dans Seurat non montrées ici

### Spatial variable features

>Identify features whose variability in expression can be explained to some degree by spatial location

> An alternative approach, implemented in FindSpatiallyVariables(), is to search for features exhibiting spatial patterning in the absence of pre-annotation. The default method (method = 'markvariogram), is inspired by the Trendsceek, which models spatial transcriptomics data as a mark point process and computes a ‘variogram’, which identifies genes whose expression level is dependent on their spatial location. More specifically, this process calculates gamma(r) values measuring the dependence between two spots a certain “r” distance apart. By default, we use an r-value of ‘5’ in these analyses, and only compute these values for variable genes (where variation is calculated independently of spatial location) to save time.
We note that there are multiple methods in the literature to accomplish this task, including SpatialDE, and Splotch. We encourage interested users to explore these methods, and hope to add support for them in the near future.

```{r}
brain <- FindSpatiallyVariableFeatures(brain, 
                                       assay = "SCT", 
                                       features=VariableFeatures(brain)[1:1000],
                                       selection.method = "moransi")
```

```{r}
##PB
#top.features <- head(SpatiallyVariableFeatures(brain, method = "moransi"), 6)
# dans forum pointe le pb

top.features = rownames(
  dplyr::slice_min(
    brain[["SCT"]]@meta.features,
    moransi.spatially.variable.rank,
    n = 6
  )
)

SpatialFeaturePlot(brain, features = top.features, ncol = 3, alpha = c(0.1, 1))
```



## Pseudotime

- Trajectory inference aims to reconstruct a cellular dynamic process
- 2 main steps:
  + Dimensionality reduction step: PCA, t-SNE, . . . . or graph-based
techniques . . . . or clustering methods
  + Trajectory modelling step
- Reviews:
  + [Cannoodt et al., 2016] : comparison of 10 methods
  + [Saelens et al., 2018] : comparison of 29 (among 59 existing) methods


https://github.com/dynverse/dynverse

![](images/MethodesPseudotime.png)
![](images/CompPseudoTime.png)
![](images/CompPseudotime2.png)


## Comment basculer entre Seurat / Scanpy / SingleCellExperiment

https://mojaveazure.github.io/seurat-disk/articles/convert-anndata.html
as.Seurat(<CellDataSet>) 
as.Seurat(<SingleCellExperiment>)
as.SingleCellExperiment()
https://github.com/cellgeni/sceasy
https://www.youtube.com/watch?v=como93CmnS8


- From Seurat to AnnData via h5Seurat

```{r}
# NE FONCTIONNE PAS - CMR

#library(SeuratDisk)
#class(pbmc)
#SaveH5Seurat(pbmc, filename = "pbmc.h5Seurat")
#Convert("pbmc.h5Seurat", dest = "h5ad")
```

> You can write out the Seurat object to an .h5ad file using the write_h5ad function:

```{r}
#write_h5ad(pbmc, "pbmc.h5ad")
```

>If you need more customized conversion, you first need to convert the Seurat object to an AnnData object. Again note that there is no one-to-one mapping possible between the AnnData and SeuratObject data structures, so some information might be lost during conversion. It is recommended to carefully inspect the converted object to ensure that all necessary information has been transferred.

>See ?as_AnnData for more details on how to customize the conversion process. Example:

```{r}
#library(anndataR)
#as_AnnData(
#  pbmc,
#  assay_name = "RNA",
#  x_mapping = "data",
#  layers_mapping = c(foo = "counts")
#)
```


- From Scanpy to Seurat

```{r}
#library(anndataR)
#library(Seurat)

#h5ad_file <- system.file("extdata", "example.h5ad", package = "anndataR")
```

>Read the .h5ad file and convert it to a Seurat object:

```{r}
#seurat_obj <- read_h5ad(h5ad_file, as = "Seurat")
#seurat_obj
```

>Note that there is no one-to-one mapping possible between the AnnData and SeuratObject data structures, so some information might be lost during conversion. It is recommended to carefully inspect the converted object to ensure that all necessary information has been transferred.

>See ?as_Seurat for more details on how to customize the conversion process. For instance:

```{r}
#adata$as_Seurat(
#  assay_name = "ADT",
#  layers_mapping = c(counts = "dense_counts", data = "dense_X")
#)
```

- From Seurat to SingleCellExperiment (sce)


## Comment basculer entre Seurat / Scanpy / SingleCellExperiment (Vincent)

- `SeuratDisk`: the solution provided by Seurat to convert to various format $\rightarrow$ not working
- `anndata2ri`: a python package developped to convert `AnnData`$\Leftrightarrow$`SingleCellExperiment`
- `zellkonverter`: a python package developped to convert `SingleCellExperiment`$\rightarrow$ various objects.
- `Seurat`$\rightarrow$`AnnData` can be done by hand $\rightarrow$ [details here](https://jr-leary7.github.io/quarto-site/tutorials/Seurat_AnnData_Conversion.html)

```{r}
if (!dir.exists("conversion_files/")) {
  dir.create("conversion_files")
}
```

```{r}
sce_ifnb <- as.SingleCellExperiment(ifnb)
```


```{r,eval=F}
library(zellkonverter)
library(reticulate)
writeH5AD(sce_ifnb, file = "conversion_files/sce_ifnb.h5ad")
```

```python

import anndata as ad
adata = ad.read('conversion_files/sce_ifnb.h5ad', backed='r')
adata
AnnData object with n_obs × n_vars = 13668 × 14053 backed at 'conversion_files/sce_ifnb.h5ad'
    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'stim', 'seurat_annotations', 'RNA_snn_res.0.5', 'seurat_clusters', 'donor_id', 'celltype.stim', 'ident'
    uns: 'X_name'
    obsm: 'INTEGRATED.CCA', 'PCA', 'UMAP', 'UMAP.UNINTEGRATED'
    layers: 'logcounts'

```

Stay in R:

```{r,eval=F}
adata <- SCE2AnnData(sce_ifnb)
adata
```

Tuto by hand: https://jr-leary7.github.io/quarto-site/tutorials/Seurat_AnnData_Conversion.html

Est-ce que je l'ajoute et que je teste si ça marche ? 

### Appendix

- Commandes Seurat : https://satijalab.org/seurat/articles/essential_commands



