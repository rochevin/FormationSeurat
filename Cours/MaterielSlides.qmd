---
title: "Materiel pour slides"
format:
  html:
    toc: true
    toc-depth: 2
    toc-location: left
    number-sections: true
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
execute:
  cache: true
---


# Introduction

## Pour suivre la formation

### Installation sur votre ordinateur

Mettre ici les infos pour la mise en place .....

### Packages nécessaires

```{r}
library(Seurat)
library(patchwork)
library(tidyverse)
library(dplyr)
library(corrplot)
library(clustree)
library(SeuratData)
library(reshape2)
library(ggplot2)
```

### Objectifs de la formation

A FAIRE


## Qu'est-ce-que les données de single-cell RNA-seq ? 

### bulk RNA-seq vs single-cell RNAseq

- Principe du bulk RNA-seq

![bulkRNAseq](images/BulkRNA.png)
- Principe du single-cell RNA-seq (scRNAseq)

![scRNAseq](images/singlecell.png)

<!--![bulk vs scRNAseq](images/scRNAseq.png)-->


## De la manip à la fin de la bio-informatique 

### Différentes technologies

???????


### Alignement - filtrage 

- Après la manip, passage par la bioinformatique
- Alignement des séquences, analyse des cellules que l'on peut retenir, ....

### Avec CellRanger

![](images/10XGenomics.png)
![](images/CellRanger-1.png)
![](images/CellRanger-Pos.png)

https://www.10xgenomics.com/support/software/cell-ranger/latest/algorithms-overview/cr-gex-algorithm

![](images/CellRanger-3.png)
![](images/CellRanger-2.png)

### Après la bio-informatique

- On récupère les données sous forme de fichiers ????? 

## De la question bio à la question stat

### Biological questions

:::: {.columns}
::: {.column width="50%"}
- Are there distinct subpopulations of cells? 
- For each cell type, what are the marker genes? 
- How visualize the cells? 
- Are there continuums of differentiation / activation cell states? 
- ...
:::
::: {.column width="50%"}
![](images/QBio.jpg)
(\tiny Rostom et al, FEBS 2017)
:::
:::


### Statistical analysis
:::: {.columns}
::: {.column width="50%"}
- Clustering of cells 
- Variable (gene) selection in learning or differential analysis (hypothesis testing) 
- Reduction dimension 
- Network inference
- Pseudo-time inference
- ...
:::
::: {.column width="50%"}
![](images/QBio.jpg)
(\tiny Rostom et al, FEBS 2017)
:::
:::

## Les packages pour analyser les données de scRNAseq

### Number of available tools for scRNAseq data
:::: {.columns}
::: {.column width="50%"}
![](images/Nbtools.png)
:::
::: {.column width="50%"}
![](images/LogoscRNAtools.png)
Many packages are released regularly for scRNAseq data analysis.
You can follow the news in the "Updates" section of scRNA-tools.
<!--
\underline{\url{https://www.scrna-tools.org/updates}}} 
-->
:::
:::
![](images/Nbtools2.png)


### Some bio-info-stat. pipelines/workflows

:::: {.columns}
::: {.column width="50%"}
- [Seurat](https://satijalab.org/seurat/) <!--\cite{Satija15}-->
![](images/Seurat.png)


- [SCANPY](https://github.com/theislab/Scanpy)<!--\cite{scanpy:wolf18}-->
![](images/Scanpy.png)

- [Sincell](https://bioconductor.org/packages/release/bioc/html/sincell.html) 
<!--\cite{Sincell15} -->	![](images/sincell.png)

- [simpleSingleCell](https://bioconductor.org/packages/release/workflows/html/simpleSingleCell.html)
<!--\cite{LunWorkflow16}-->
![](images/WorkflowLun.png)
![](images/simpleSingleCell.png)
:::
::: {.column width="50%"}
- [SINCERA](https://research.cchmc.org/pbge/sincera.html)    
<!--\cite{GuoSINCERA15}-->
![](images/SINCERAschema.png)

- [Scedar](https://github.com/logstar/scedar) <!--\cite{scedar}-->
![](images/Scedar.png)

- $\ldots$
:::
:::

### Attention au type d'objet

-   Expliquer que chaque pipeline a son type d'Objet
    -   Seurat en R $\longrightarrow$ Seurat Object
    -   Scanpy en python $\longrightarrow$ AnnData class
    -   SingleCellExperiment 
- Il existe des fonctions qui permettent de passer de l'un à l'autre

- Dans la suite on va travailler avec Seurat

A VOIR COMMENT ON ARTICULE AVEC AnnData juste après. 
Peut-etre le mettre dans pour aller plus loin quand on veut basculer dans scanpy et/ou quand on doit passer par sce.  

### AnnData

![Représentation schématique de l'objet AnnData](images/anndata_schema.svg){width="50%" fig-align:"center"}

* `X`: Données de comptage sous forme de matrice creuse (sparse):
  * ```python
  adata.X
  <100x2000 sparse matrix of type '<class 'numpy.float32'>'
	with 126526 stored elements in Compressed Sparse Row format>
    ```
  * ```python
  adata.obs_names = [f"Cell_{i:d}" for i in range(adata.n_obs)]
  adata.var_names = [f"Gene_{i:d}" for i in range(adata.n_vars)]
  print(adata.obs_names[:10])
  Index(['Cell_0', 'Cell_1', 'Cell_2', 'Cell_3', 'Cell_4', 'Cell_5', 'Cell_6',
       'Cell_7', 'Cell_8', 'Cell_9'],
      dtype='object')
    ```
* `obs`/`var`: Metadonnées des observations variables 
* `Layers`: `adata.layers["log_transformed"] = np.log1p(adata.X)`
* `obsm`/`varm` : Métriques ou des données dérivées supplémentaires liées aux observations / variables (Résultat ACP)
* `uns`: Données non structurées (paramètres de l'analyse, autres métadonnées, ...)
* `obsp`/`varp`: Relations par paires entre les cellules


## Exemple pour la suite

### Présentation des données

### Création de l'objet Seurat

```{r init}
#| message: false
#| warning: false

# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "data/pbmc3k_filtered_gene_bc_matrices/filtered_gene_bc_matrices/hg19/")

# Initialize the Seurat object with the raw (non-normalized data).
pbmc <- CreateSeuratObject(counts = pbmc.data, 
                           project = "pbmc3k", 
                           min.cells = 3, 
                           min.features = 200)
class(pbmc)
pbmc
```

### Contenu du SO

- $C$= `r ncol(pbm)` cellules décrites par `$G=$ `r nrow(pbmc)`gènes
- Les comptages bruts sont dans `pbmc@assays$RNA$counts`

```{r}

dim(pbmc)
pbmc@assays$RNA$counts[10:20,1:15]
Assays(pbmc)
```

![](images/SO-1.png)


### Spécificités des données scRNAseq

- $C$ cellules décrites par  $G$ gènes:  $C\leq G$ or $C \approx G$ $\Longrightarrow$ grande dimension
- Mesures: $y_{cg}\in\mathbb{N}$  = count expression measure of gene $g$ in cell $c$. Ce sont des comptages
- Technical and biological noise
- High variability
- Zero-inflated data $\Longrightarrow$ "sparsity" 
($\geq 80\%$ of zeros per raw, dropouts). 


# Pipeline d'analyse d'une condition biologique

## Contrôle qualité

### QC metrics : `nCount_RNA` et `nFeature_RNA`

- A la création de l'objet **SO**, calcul de `nCount_RNA` et `nFeature_RNA`, disponibles dans `meta.data`

 <!-- + orig.ident: this often contains the sample identity if known,        but will default to project as we had assigned it
 -->
 
  + nCount_RNA: number of UMIs per cell
  + nFeature_RNA: number of genes detected per cell

![](images/SO-2.png)


```{r}
head(pbmc@meta.data)
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA"), ncol = 2)
```

**Mettre le schema evolué avec meta.data**

### QC metrics

- Calculate some additional metrics for plotting:

  + number of genes detected per UMI: 
this metric with give us an idea of the complexity of our dataset (more genes detected per UMI, more complex our data)
  
```{r}
pbmc$log10GenesPerUMI <- log10(pbmc$nFeature_RNA) /   log10(pbmc$nCount_RNA)
VlnPlot(pbmc, features = c("log10GenesPerUMI"))
```
  
  
  + mitochondrial ratio: this metric will give us a percentage of cell reads originating from the mitochondrial genes
The number of genes per UMI for each cell is quite easy to calculate, and we will log10 transform the result for better comparison between samples. function `PercentageFeatureSet()` 

```{r}
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, 
                                             pattern = "^MT-")
head(pbmc@meta.data, 5)
VlnPlot(pbmc, features = c("percent.mt"))
```

```{r}
plot1 <- FeatureScatter(pbmc, 
                        feature1 = "nCount_RNA", 
                        feature2 = "percent.mt")
plot2 <- FeatureScatter(pbmc, 
                        feature1 = "nCount_RNA", 
                        feature2 = "nFeature_RNA")
plot1 + plot2
```

![](images/SO-3.png)


### Filtrage des cellules 

- A l'aide de ces indicateurs, filtrage préliminaire des cellules 

```{r}
dim(pbmc)
pbmc <- subset(pbmc, 
               subset = nFeature_RNA > 200 & 
                        nFeature_RNA < 2500 & 
                        percent.mt < 5)
dim(pbmc)
```

On ne conserve que $C=$ `r ncol(pbmc)` cellules pour la suite de l'étude. 


## Normalisation

### Why do we need to normalize the data ?

- We need to remove technical biases in order to 
  + to be able to compare cells
  
![](images/motivNormalisation.png)

Images from https://www.biostars.org/p/349881/

> The 2 libraries have the same RNA composition.
> But the condition B has 3 times more reads than
the condition A.
We need to correct for differences in library size.

  + to be able to compare genes
  
- Take into account the sparsity of the count matrix  

### Normalization in Seurat

- Many possible strategies for normalized data
- In Seurat, function `NormalizeData(object,normalization.method= ...,)`

  + "LogNormalize" : Feature counts for each cell are divided by the total counts for that cell and multiplied by the scale.factor. This is then natural-log transformed using log1p

  + "CLR" : Applies a centered log ratio transformation
  
  >clr_function <- function(x) {
  >        return(log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm   >= TRUE) / length(x = x)))))}
  >log1p(x) computes log(1+x) accurately also for |x| << 1.

  + "RC" (Relative counts): Feature counts for each cell are divided by the total counts for that cell and multiplied by the scale.factor. 
  No log-transformation is applied. 
  For counts per million (CPM) set scale.factor = 1e6

  + "SCTransform" : il faut passer par une autre fonction `SCTransform()`
The use of SCTransform replaces the need to run NormalizeData, FindVariableFeatures, or ScaleData (described below.)
In Seurat v5, SCT v2 is applied by default. You can revert to v1 by setting vst.flavor = 'v1'

<!--
Article: Comparison and evaluation of statistical
error models for scRNA-seq.
Saket Choudhary and Rahul Satija
-->

### Example

```{r}
 pbmc <- NormalizeData(pbmc, 
                       normalization.method = "LogNormalize", 
                       scale.factor = 10000)
pbmc@assays$RNA$data[10:20,1:5]
# pbmc[["RNA"]]$data[10:20,1:10]
# dim(pbmc[["RNA"]]$data)
```
  
```{r,echo=F}
aux<-data.frame(brut=apply(pbmc@assays$RNA$counts,2,sum),
                norm=apply(pbmc@assays$RNA$data,2,sum))
ggplot(melt(aux),aes(x=variable,y=value))+
  geom_boxplot()
rm(aux)
```
  
![](images/SO-4.png)  
  
  
### Identification des gènes HVG

- HVG = High Variable Gene (feature)

- Identification of highly variable features
- Exhibit high cell-to-cell variation in the dataset 

![](captureContent/ExplicationHVG-Seurat.png) 

> **Feature selection for individual datasets**
In each dataset, we next aimed to identify a subset of features (e.g., genes) exhibiting high variability across cells, and therefore represent heterogeneous features to prioritize for downstream analysis. Choosing genes solely based on their log-normalized single-cell variance fails to account for the mean-variance relationship that is inherent to single-cell RNA-seq. Therefore, we first applied a variance-stabilizing transformation to correct for this [Mayer et al., 2018; Hafemeister and Satija, 2019].

> To learn the mean-variance relationship from the data, we computed the mean and variance of each gene using the unnormalized data (i.e., UMI or counts matrix), and applied log10 transformation to both. We then fit a curve to predict the variance of each gene as a function of its mean, by calculating a local fitting of polynomials of degree 2 (R function loess, span = 0.3). This global fit provided us with a regularized estimator of variance given the mean of a feature. As such, we could use it to standardize feature counts without removing higher-than-expected variation.

> Given the expected variances, we performed the transformation $z_{i,j} = \frac{x_{i,j} - \bar{x}_i}{\sigma_i}$

> where $z_{i,j}$ is the standardized value of feature $i$ in cell $j$, $x_{i,j}$ is the raw value of feature $i$ in cell $j$, $\bar{x}_i$ is the mean raw value for feature $i$, and $\sigma_i$ is the expected standard deviation of feature $i$ derived from the global mean-variance fit. To reduce the impact of technical outliers, we clipped the standardized values to a maximum value of $\sqrt{N}$, where $N$ is the total number of cells. For each gene, we then computed the variance of standardized values across all cells. This variance represents a measure of single-cell dispersion after controlling for mean expression, and we use it directly to rank the features. Unless otherwise noted, we selected the 2,000 genes with the highest standardized variance as “highly variable.” This procedure is implemented in the FindVariableFeatures function in Seurat v3 (selection.method = “vst”).

Stuart et al. (Cell, 2019). Comprehensive Integration of Single-Cell Data 


Dans la fonction `FindVariableFeatures(object,selection.method=...,)` : 

- "vst": First, fits a line to the relationship of log(variance) and log(mean) using local polynomial regression (loess). Then standardizes the feature values using the observed mean and expected variance (given by the fitted line). Feature variance is then calculated on the standardized values after clipping to a maximum (see clip.max parameter).

- "mean.var.plot" (mvp): First, uses a function to calculate average expression (mean.function) and dispersion (dispersion.function) for each feature. Next, divides features into num.bin (default 20) bins based on their average expression, and calculates z-scores for dispersion within each bin. The purpose of this is to identify variable features while controlling for the strong relationship between variability and average expression

- "dispersion" (disp): selects the genes with the highest dispersion values

```{r}
pbmc <- FindVariableFeatures(pbmc, 
                             selection.method = "vst", 
                             nfeatures = 2000)
length(VariableFeatures(pbmc))
# Identification du top 10 des HVG
top10<-head(VariableFeatures(pbmc), 10)
top10
# plot variable features with and without labels
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot2
```



## Réduction de dimension

### Objectifs de la réduction de dimension

- Minimize curse of dimensionality\vspace*{0.3cm}
- Allow visualization\vspace*{0.3cm}
- Reduce computational time\vspace*{0.3cm}
- \ldots \vspace*{0.3cm}
- But beware of the interpretations after!\vspace*{0.3cm}

### Several methods

Several methods are available:

- **PCA**, 
- **t-SNE**, 
- **UMAP**, 
- ZIFA, 
- ZINB-WaVe, 
- SWNE, 
- Diffusion MAP, 
- pCMF, 
- $\ldots$ 

Comparaison des rendus avec [Sleepwalk](https://anders-biostat.github.io/sleepwalk/#)

### Scaling the data

Vignette Seurat: 

- Shifts the expression of each gene, so that the mean expression across cells is 0
- Scales the expression of each gene, so that the variance across cells is 1
This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
- The results of this are stored in pbmc[["RNA"]]$scale.data
By default, only variable features are scaled.
You can specify the features argument to scale additional features

Dans Seurat, fonction `ScaleData()`

```{r}
pbmc<-ScaleData(pbmc) #features = Default is variable features J (=2000 par défaut)
dim(pbmc@assays$RNA$scale.data) # on a plus que J=2000 gènes 
#d'où des soucis (warnings) dans la suite mais c'est plus rapide pour la formation ????
pbmc[["RNA"]]$scale.data[10:20,1:10]
```

![](images/SO-6.png)




### Principle of PCA
-   explication du principe de la PCA : changement de repère cherchant à maximiser l'inertie axiale (inertie des projetés)

```{r}
#| fig.width: 8
#| fig.height: 4 
#| fig.cap: Analyse en composante principale du jeu de données iris sur les deux premières dimensions.
X <- iris[,c(1,3)]
# Run PCA
pca <- princomp(X)
load <- loadings(pca)
slope <- load[2, ] / load[1, ]
cmeans <- apply(X, 2, mean)
intercept <- cmeans[2] - (slope * cmeans[1])


# Plot perpendicular segments

df<-data.frame(X)
img1 <- ggplot(df,aes(Sepal.Length,Petal.Length))+
  geom_point()+
  geom_point(data = cmeans %>% t %>%  as.data.frame(),aes(Sepal.Length,Petal.Length),col="red",size=4) +
  geom_abline(intercept=intercept[1],slope=slope[1],linetype="dashed")+
  geom_abline(intercept=intercept[2],slope=slope[2],linetype="dashed")+
  theme_classic(base_size=16) + coord_fixed()


img2 <- (pca$scores) %>% as.data.frame() %>% ggplot(aes(Comp.1,-1*Comp.2)) + geom_point()+ theme_classic(base_size=16) + geom_vline(xintercept = 0,linetype="dashed")+ geom_hline(yintercept = 0,linetype="dashed")

design <- "AB"
wrap_plots(A=img1,B=img2, design = design,tag_level="new")+  plot_annotation(tag_levels = "A")
```

- Les axes de l'ACP sont projetés sur les dimensions d'origine et passent par la moyenne (rouge).
- Projection des points dans l'espace de l'ACP.

![](images/ACP-Fenelon.png)
![](images/repereACP.png)

+ exemple dans cours de 3MIC


### PCA with Seurat

-   scale + runPCA()
-   explication des sorties de Seurat
-   expliquer où c'est stocké dans l'objet

```{r}
#| message: false
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))
pbmc@reductions$pca
str(pbmc@reductions$pca)
head(pbmc@reductions$pca@cell.embeddings)    #head(pbmc[["pca"]]@cell.embeddings)
#head(Embeddings(pbmc@reductions$pca))
head(pbmc@reductions$pca@feature.loadings)
```

- cell.embedding : coordonnées des projections des cellules sur les différents axes princpaux
- feature.loadings : correlations entre genes et composantes principales

```{r}
corrplot(pbmc[["pca"]]@feature.loadings[c("CST3", "TYROBP", "LST1", "AIF1", "FTL"),1:5],method="ellipse")
```

```{r}
print(pbmc[["pca"]], dims = 1:3, nfeatures = 5)
```

```{r}
VizDimLoadings(pbmc, dims = 1:2, reduction = "pca")
```

```{r}
DimPlot(pbmc, reduction = "pca") + NoLegend()
```

```{r}
DimHeatmap(pbmc, dims = 1:2, cells = 500, balanced = TRUE)
```

```{r}
ElbowPlot(pbmc)
```

Mais probleme de l'ACP sur les données scRNAseq

- C'est une méthode de réduction de dimension linéaire
- Elle est sensible à la sparsité des données scRNAseq 
- C'est donc utilisé pour réduire le jeu de données pour la suite de l'étude. 


### t-SNE

t-Distributed stochastic neighbor embedding is a state-of-the-art dimensionality reduction algorithm for non-linear data representation that produces a low-dimensional distribution of high-dimensional data (Maaten and Hinton, 2008; Van Der Maaten, 2014). It excels at revealing local structure in high-dimensional data. t-SNE is based on the SNE (Hinton and Roweis, 2002), which starts from converting the high-dimensional Euclidean distances between data points into conditional probabilities that represent similarities. The main idea and the modifications of t-SNE are (1) the symmetric version of SNE and (2) using a Student’s t distribution to compute the similarity between two points in the low-dimensional space.

![](images/schemetSNE.png)

Dans Seurat, en raison de la dimension des données, part avec les données de l'ACP (reduction="pca" par défaut). Détermination des voisins par KNN puis t-SNE avec la fonction RunTSNE

```{r}
#| message: false
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- RunTSNE(pbmc, dims = 1:10)
DimPlot(pbmc, reduction = "tsne")
```


### UMAP

-   utilise au démarrage les coordonnées de PCA
-   explication du principe de l'UMAP
-   illustration

Uniform manifold approximation and projection is a dimension reduction technique that can be used not only for visualization similarly to t-SNE but also for general non-linear dimension reduction. Compared with t-SNE, UMAP retains more global structure with superior run-time performance (McInnes et al., 2018; Becht et al., 2019).

The algorithm is based on three assumptions about the data: (a) the data are uniformly distributed on the Riemannian manifold; (b) the Riemannian metric is locally constant (or can be approximated); and (c) the manifold is locally connected. According to these assumptions, the manifold with fuzzy topology can be modeled. The embedding is found by searching the low-dimensional projection of the data with the closest equivalent fuzzy topology. In terms of model construction, UMAP includes two steps: (1) building a particular weighted k-neighbor graph using the nearest-neighbor descent algorithm (Dong et al., 2011) and (2) computing a low-dimensional representation which can preserve desired characteristics of this graph.

https://www.youtube.com/watch?v=jth4kEvJ3P8


```{r}
#| message: false
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- RunUMAP(pbmc, dims = 1:10)
DimPlot(pbmc, reduction = "umap")
```


## Clustering

### Principe / objectif du clustering

- Goal : organizing cells into groups whose members are similar in some way 
- Fundamental question : What is meant by "similar cells"? 
- The number of clusters $K$ is unknown 
- Typical clustering methods : 
	+ Hierarchical clustering (CAH)
	+ Kmeans clustering
	+ Graph-based clustering
	+ Model-based clustering 
	+ ...


### Some methods

<!--
\textcolor{blue}{\tiny \cite{Duo18}}\\
\textcolor{blue}{\tiny \cite{Freytag18}}\\
\textcolor{blue}{\tiny \cite{petegrosso2019}}\\ 
\textcolor{blue}{\tiny \cite{zhang2020review}}
-->

![](images/TableauReviewMethodesClust.png)

### Dans Seurat

- Calculate k-nearest neighbors and construct the SNN graph
(based on Euclidean distance in PCA space)
- Optimize a modularity function to determine clusters - Louvain’s
algorithm
- Sensitive choice of the resolution parameter
(involve the number of clusters K)

-   explication du principe de Louvain
![](images/Louvain.png)
-   nécessite un parametre de résolution (pas nb de clusters K)
-   exemple pour une valeur de résolution (FindNeighbour + FindCluster)
-   exemple de plot sur UMAP, effectifs par classe, ....

```{r}
pbmc <- FindClusters(pbmc, resolution = 0.5)
table(pbmc@meta.data$seurat_clusters)
DimPlot(pbmc, reduction = "umap") # par défaut il colore par seurat_clusters qui n'existait pas avant ?!
```

### Choix de la resolution ?

- faire tourner pour plusieurs résolution
- visualisation par ARI, clustree des différents clusterings obtenus
- En afficher deux sur UMAP figue dissociée
- on peut tous les stocker dans objet SO mais attention à bien positionner celui étudié pour la suite

```{r}
list_resolutions<-seq(0.1,1,by=0.1)
for (r in list_resolutions){
    pbmc <- FindClusters(pbmc, resolution = r, cluster.name = paste0("Clusters_", r))
}
head(pbmc@meta.data)
```

```{r}
#| message: false

# Visualisation ARI - fonctions auxiliaires
source("Cours/FunctionsAux.R")
ari_matrix <- ARI_matrix(pbmc, list_resolutions)
heatmapari(ari_matrix, list_resolutions)

# Nb de clusters
NbCluster_gg(pbmc, list_resolutions)

# Comparaison visuelle des clusterings obtenus
p1<-DimPlot(pbmc,reduction = "umap",group.by = "Clusters_0.3")
p2<-DimPlot(pbmc,reduction = "umap",group.by = "Clusters_0.4")
p1+p2

# clustree

clusterplot<-clustree(pbmc, prefix = "Clusters_")
clusterplot
```

Dans la suite, on va se focaliser sur le clustering obtenu avec la resolution 0.5

```{r}
Idents(pbmc)<-pbmc@meta.data$Clusters_0.5
table(Idents(pbmc))
EffPlot(pbmc,resolution=0.5)
pbmc$seurat_clusters<-pbmc@meta.data$Clusters_0.5
DimPlot(pbmc,reduction = "umap")
```


## Marker gene

### Question / objectif

- formalisation du problème
- naturellement on est sur une question de test

- Aim: After the identification of cell clusters, we want to find marker genes for each cluster
- marker gene for one cluster $\mathcal C_k$: differential expressed gene for this single cluster $\mathcal G_1 = \mathcal C_k$ (specified in ident.1), compared to all other cells $\mathcal G_2 = \{1,\ldots,n\} \backslash \mathcal C_k$.

- FindMarkers() et FindAllMarkers()

### Wilcoxon

- explication du test de Wilcoxon

For a fixed gene $g$, 2 samples
$\underline{X}=(X_{gc}; c\in\mathcal G_1)$ and $\underline{Y}=(X_{gc}; c\in\mathcal G_2)$

Are these two samples equally distributed or not? 

```{r,echo=F}
pbmcaux<-pbmc
pbmcaux$aux<-pbmc$Clusters_0.5
pbmcaux$aux[pbmc$Clusters_0.5==3]<-"3"
pbmcaux$aux[pbmc$Clusters_0.5!=3]<-"0"
Idents(pbmcaux)<-pbmcaux$aux
RidgePlot(pbmcaux,features=c("CD79A","GNG5"))
```

- correction de test multiple
Dans Seurat, Bonferroni

- sur l'exemple, montrer le grand nombre de gènes sélectionnés

```{r}
GeneMkWilcox3<-FindMarkers(pbmc,test.use = "wilcox",ident.1 = 3,logfc.threshold=0.5)
head(GeneMkWilcox3)
sum(GeneMkWilcox3$p_val_adj<0.01)
```


### Problème de double-dipping

- mettre l'exemple classique sur une classe gaussienne

![](images/doubledipping.png)

- reste un probleme ouvert en statistique, loin d'une solution pour le scRNAseq

### AUC (area under the ROC curve) 

- explication de l'AUC. ($2\times |\mbox{AUC}-0.5|$ )
- attention ce n'est pas un test
- choix du seuil ?

![](images/AUROC1.png)
![](images/AUC.png)


- application sur l'exemple avec FindMarkers

```{r}
GeneMkAUC3<-FindMarkers(pbmc,test.use = "roc",ident.1 = 3,logfc.threshold=0.5)
head(GeneMkAUC3)
```

### Autres indicateurs dispo

- pct.1 / pct.2 : pct1 and pct2 : $\%$ of cells where the gene is expressed in each group
- log2FC (avg$\_$logFC) = log fold-change of the average expression between the two groups
- Choice of thresholds ?

```{r}
head(GeneMkAUC3)
```



### Exemple

- on fusionne les deux tableaux obtenus par AUC et wilcox
- on applique des filtres pour retenir un groupe de genes marqueurs pour chaque cluster
- visualisation par DoHeatmap
- dotPlot
- ridgePlot


```{r}
GeneMkAUC3$gene<-rownames(GeneMkAUC3)
GeneMkWilcox3$gene<-rownames(GeneMkWilcox3)
GeneMkCl3_merge<-merge(GeneMkAUC3,GeneMkWilcox3[,c(1,5,6)],by="gene")
head(GeneMkCl3_merge)
```


```{r}
SelectGene<-GeneMkCl3_merge%>%
    filter(myAUC>0.9)%>%
    filter(avg_log2FC>2)%>%
    arrange(desc(myAUC))
head(SelectGene)
```

```{r}
VlnPlot(pbmc, features = SelectGene$gene[1:3], layer = "counts", log = TRUE)
VlnPlot(pbmc, features = SelectGene$gene[1:3], layer = "data", log = TRUE)
```

```{r}
FeaturePlot(pbmc, features = SelectGene$gene[1:3])
```

```{r}
DotPlot(pbmc,features = SelectGene$gene[1:3])
```

```{r}
RidgePlot(pbmc,features = SelectGene$gene[1:3])
```


### Exemple complet

- reprise avec la fonction FindAllMArkers() pour le faire automatiquement pour toutes les classes. 

```{r,eval=F}
GeneMkWilcox<-FindAllMarkers(pbmc,logfc.threshold = 0.1,test.use = "wilcox")
saveRDS(GeneMkWilcox, file = "data/GeneMkWilcox.rds")
GeneMkAUC<-FindAllMarkers(pbmc,logfc.threshold = 0.1,test.use = "roc")
saveRDS(GeneMkAUC, file = "data/GeneMkAUC.rds")
```

```{r}
GeneMkWilcox<-readRDS("data/GeneMkWilcox.rds")
GeneMkWilcox$gene<-rownames(GeneMkWilcox)
head(GeneMkWilcox)

GeneMkAUC<-readRDS("data/GeneMkAUC.rds")
GeneMkAUC$gene<-rownames(GeneMkAUC)
head(GeneMkAUC)
```


```{r}
## PB de merge car gene et cluster ! A revoir
## il faut merger les genes pour chaque cluster fixé
    ##GeneMk_merge<-merge(GeneMkAUC,GeneMkWilcox[,c(1,5,6,7)],by="gene")
    ##head(GeneMk_merge)
GeneMk_merge<-GeneMkWilcox%>%
              select(c("p_val","p_val_adj","cluster","gene"))%>%
              left_join(GeneMkAUC,by=c("gene","cluster"))
GeneMk_merge<-GeneMk_merge[,c(4,3,1:2,5:10)]%>%
              arrange(cluster,desc(myAUC))
GeneMk_merge[65:75,]  ## pourquoi ce n'est pas dans GeneMkAUC ???   
```


```{r}
GeneMkAUC %>%
    group_by(cluster) %>%
    arrange(desc(myAUC))%>%
    filter(avg_log2FC > 1) %>%
    slice_head(n = 10) %>%
    ungroup() -> top10
DoHeatmap(pbmc, features = top10$gene) + NoLegend()
```


### un groupe contre un autre

- expliquer que l'on peut faire la même chose mais en précisant une classe contre une autre, un groupe de classes contre un autre groupe de classes
- fonction FindMarkers
- le faire sur l'exemple

```{r}
GeneMkCl3vsCl5<-FindMarkers(pbmc,test.use="roc",ident.1=3,ident.2=5,logfc.threshold=0.1)
ggplot(GeneMkCl3vsCl5,aes(x=myAUC))+geom_density()
quantile(GeneMkCl3vsCl5$myAUC,seq(0.9,1,0.01))
SelectCl3vsCl5<-GeneMkCl3vsCl5%>%
  filter(myAUC>0.7)%>%
  arrange(desc(avg_log2FC))
dim(SelectCl3vsCl5)
```

```{r}
DoHeatmap(pbmc[,which(pbmc$Clusters_0.5 %in% c(3,5))], features = rownames(SelectCl3vsCl5),assay = "RNA",slot = "data") + NoLegend()
```

```{r}
FeaturePlot(pbmc, features = rownames(SelectCl3vsCl5)[1:3])
```

```{r}
DotPlot(pbmc,features = rownames(SelectCl3vsCl5)[1:10])+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}
RidgePlot(pbmc,features = rownames(SelectCl3vsCl5)[1])
```

# Pipeline d'analyse pour deux (plusieurs) conditions biologiques

### Context


### REM

A réfléchir : 

- Si on a deux fichiers de données diff --> 2 objets Seurat normalisés séparément puis intégration
- Dans l'exemple ifnb c'est sous forme de layers (Seurat V5)



### Example

The object contains data from human PBMC from two conditions, interferon-stimulated and control cells (stored in the stim column in the object metadata). We will aim to integrate the two conditions together, so that we can jointly identify cell subpopulations across datasets, and then explore how each group differs across conditions

In previous versions of Seurat, we would require the data to be represented as two different Seurat objects. In Seurat v5, we keep all the data in one object, but simply split it into multiple ‘layers’. To learn more about layers, check out our Seurat object interaction vignette.


```{r}
# devtools::install_github('satijalab/seurat-data')
InstallData("ifnb")
ifnb <- LoadData("ifnb")
```

```{r}
Assays(ifnb)
Layers(ifnb) # difference entre count et data ??

dim(ifnb)    # 14053 13999
table(ifnb$orig.ident)
table(ifnb$stim)
```

On splitte selon les deux conditions (counts.CTRL et counts.STIM)

```{r}
ifnb[["RNA"]] <- split(ifnb[["RNA"]], f = ifnb$stim)
ifnb

dim(ifnb[["RNA"]]$counts.CTRL)
dim(ifnb[["RNA"]]$counts.STIM)
```

### Normalization

- Fait la normalisation comme vu précédemment pour chaque matrice de counts 
(counts.CTRL --> data.CTRL et counts.STIM--> data.STIM)


```{r}
ifnb <- NormalizeData(ifnb)

ifnb@assays$RNA$data.CTRL[1:10,1:10]
ifnb@assays$RNA$data.STIM[1:10,1:10]
```

### HVG 

- HVG 
  + ?: il le fait pour chaque condition ? --> A priori oui car on a l'affichage par condition dans la console lors de l'execusion
  + ? comment on récupère le plot par condition ? )
  
```{r}
ifnb <- FindVariableFeatures(ifnb)

top10<-head(VariableFeatures(ifnb), 10)
plot1<-VariableFeaturePlot(ifnb)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
```

### Dimension reduction sans integration

- En fait ça fait la réduction de dimension de toutes les données ensembles sans intégration ??

```{r}
ifnb <- ScaleData(ifnb)
ifnb <- RunPCA(ifnb)
ifnb <- FindNeighbors(ifnb, dims = 1:30, reduction = "pca")
ifnb <- RunUMAP(ifnb, dims = 1:30, reduction = "pca", reduction.name = "umap.unintegrated")
DimPlot(ifnb, reduction = "umap.unintegrated", group.by = c("stim"))
```


### Integration

>We now aim to integrate data from the two conditions, so that cells from the same cell type/subpopulation will cluster together.

>We often refer to this procedure as intergration/alignment. When aligning two genome sequences together, identification of shared/homologous regions can help to interpret differences between the sequences as well. Similarly for scRNA-seq integration, our goal is not to remove biological differences across conditions, but to learn shared cell types/states in an initial step - specifically because that will enable us to compare control stimulated and control profiles for these individual cell types.

>The Seurat v5 integration procedure aims to return a single dimensional reduction that captures the shared sources of variance across multiple layers, so that cells in a similar biological state will cluster. The method returns a dimensional reduction (i.e. integrated.cca) which can be used for visualization and unsupervised clustering analysis. For evaluating performance, we can use cell type labels that are pre-loaded in the seurat_annotations metadata column.

- Seurat function: IntegrateLayers() 
- Five integration methods :

  + Anchor-based CCA integration (method=CCAIntegration)
  CCA = Canonical Correlation Analysis

![](images/CCA-Seurat.png)
Explication: https://xinmingtu.cn/blog/2022/CCA_dual_PCA/


  + Anchor-based RPCA integration (method=RPCAIntegration)
  + Harmony (method=HarmonyIntegration)
  
![](images/HarmonyIntegration.png)  
  
  + FastMNN (method= FastMNNIntegration)
  + scVI (method=scVIIntegration) --> Ne semble plus être dispo
  

https://www.biorxiv.org/content/10.1101/2024.12.16.628691v1.full.pdf 
https://divingintogeneticsandgenomics.com/post/cca-alignment/
  
### Example

```{r,eval=F}
obj <- IntegrateLayers(
  object = ifnb, 
  method = CCAIntegration,
  orig.reduction = "pca", 
  new.reduction = "integrated.cca",
  verbose = FALSE
)
obj <- FindNeighbors(obj, reduction = "integrated.cca", dims = 1:30)
```

```{r}
ifnb <- IntegrateLayers(object = ifnb, 
                        method = CCAIntegration, 
                        orig.reduction = "pca", 
                        new.reduction = "integrated.cca",
                        verbose = FALSE)

# re-join layers after integration
ifnb[["RNA"]] <- JoinLayers(ifnb[["RNA"]])
```

Dimension reduction
```{r}
ifnb <- FindNeighbors(ifnb, 
                      reduction = "integrated.cca", 
                      dims = 1:30)
ifnb <- RunUMAP(ifnb, 
                dims = 1:30, 
                reduction = "integrated.cca")
```

Clustering :

```{r}
ifnb <- FindClusters(ifnb, resolution = 0.5)

# Visualization
DimPlot(ifnb, 
        reduction = "umap", 
        group.by = c("stim", "seurat_clusters"))

DimPlot(ifnb, reduction = "umap", split.by = "stim")
```


```{r}
Aux<-melt(table(Idents(ifnb),ifnb$stim))
colnames(Aux)<-c("Cluster","Condition","len")
ggplot(data=Aux, aes(x=Cluster, y=len, fill=Condition)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=len), vjust=1.6, color="white",
            position = position_dodge(0.9), size=3.5)+
  theme_minimal()
```

### Annotations

- annotation Seurat des données est disponible

```{r}
Idents(ifnb)<- "seurat_annotations"
table(Idents(ifnb))

DimPlot(ifnb, 
        reduction = "umap", 
        group.by = c("seurat_annotations"))
```




### Identify conserved cell type markers

> To identify canonical cell type marker genes that are conserved across conditions, we provide the FindConservedMarkers() function. This function performs differential gene expression testing for each dataset/group and combines the p-values using meta-analysis methods from the MetaDE R package. For example, we can calculated the genes that are conserved markers irrespective of stimulation condition in cluster 6 (NK cells).

```{r}
Idents(ifnb) <- "seurat_annotations"
nk.markers <- FindConservedMarkers(ifnb, 
                                   ident.1 = "NK", 
                                   grouping.var = "stim", 
                                   verbose = FALSE)
head(nk.markers)
```

```{r}
Idents(ifnb) <- factor(Idents(ifnb), levels = c("pDC", "Eryth", "Mk", "DC", "CD14 Mono", "CD16 Mono",
    "B Activated", "B", "CD8 T", "NK", "T activated", "CD4 Naive T", "CD4 Memory T"))

markers.to.plot <- c("CD3D", "CREM", "HSPH1", "SELL", "GIMAP5", "CACYBP", "GNLY", "NKG7", "CCL5",
    "CD8A", "MS4A1", "CD79A", "MIR155HG", "NME1", "FCGR3A", "VMO1", "CCL2", "S100A9", "HLA-DQA1",
    "GPR183", "PPBP", "GNG11", "HBA2", "HBB", "TSPAN13", "IL3RA", "IGJ", "PRSS57")
DotPlot(ifnb, features = markers.to.plot, cols = c("blue", "red"), dot.scale = 8, split.by = "stim") +
    RotatedAxis()
```

### Identify differential expressed genes across conditions

#### Si pas de replicat




#### Pseudo-bulk

D'abord ajout d'informations pour avoir des "replicats"

```{r}
# load the inferred sample IDs of each cell
ctrl <- read.table(url("https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye1.ctrl.8.10.sm.best"), head = T, stringsAsFactors = F)
stim <- read.table(url("https://raw.githubusercontent.com/yelabucsf/demuxlet_paper_code/master/fig3/ye2.stim.8.10.sm.best"), head = T, stringsAsFactors = F)
info <- rbind(ctrl, stim)

# rename the cell IDs by substituting the '-' into '.'
info$BARCODE <- gsub(pattern = "\\-", replacement = "\\.", info$BARCODE)

# only keep the cells with high-confidence sample ID
info <- info[grep(pattern = "SNG", x = info$BEST), ]

# remove cells with duplicated IDs in both ctrl and stim groups
info <- info[!duplicated(info$BARCODE) & !duplicated(info$BARCODE, fromLast = T), ]

# now add the sample IDs to ifnb 
rownames(info) <- info$BARCODE
info <- info[, c("BEST"), drop = F]
names(info) <- c("donor_id")
ifnb <- AddMetaData(ifnb, metadata = info)

# remove cells without donor IDs
ifnb$donor_id[is.na(ifnb$donor_id)] <- "unknown"
ifnb <- subset(ifnb, subset = donor_id != "unknown")
```


Ici regroupement par condition (CTRL/STIM) et par types cellulaires (sens??) et donaor ids 

```{r}
# pseudobulk
pseudo_ifnb <- AggregateExpression(ifnb, 
                                   assays = "RNA", 
                                   return.seurat = T, 
              group.by = c("stim", "donor_id", "seurat_annotations"))

head(pseudo_ifnb)
class(pseudo_ifnb)
pseudo_ifnb@assays$RNA$counts[1:10,]
```


```{r}
pseudo_ifnb$celltype.stim <- paste(pseudo_ifnb$seurat_annotations, pseudo_ifnb$stim, sep = "_")
table(pseudo_ifnb$celltype.stim)
Idents(pseudo_ifnb) <- "celltype.stim"
table(Idents(pseudo_ifnb))
```

Utilisation de DESeq2 : 

```{r}
#bulk.mono.de <- FindMarkers(object = pseudo_ifnb, 
#                         ident.1 = "CD14 Mono_STIM", 
#                         ident.2 = "CD14 Mono_CTRL",
#                         test.use = "DESeq2")
#head(bulk.mono.de, n = 10)
```



# Pour aller plus loin

## Spatial transcriptomic (ST)

### ST Data

>In the Seurat object, the spot by gene expression matrix is similar to a typical “RNA” Assay but contains spot level, not single-cell level data. The image itself is stored in a new images slot in the Seurat object. The images slot also stores the information necessary to associate spots with their physical position on the tissue image.


![](images/SpatialTransc.png)

### Example

```{r}
InstallData("stxBrain")
brain <- LoadData("stxBrain", type = "anterior1")
brain
```

Contenu de l'objet : A COMPLETER

```{r}
brain@assays$Spatial$counts[1:6,1:10]
brain@images$anterior1
```

```{r}
SpatialFeaturePlot(brain, features = "nCount_Spatial") + theme(legend.position = "right")
```


### Pipeline

- Normalization

- Dimension reduction
- **Clustering** : take into account spatial information
- Marker genes 
- ....
- Detecting spatially-variable features

### Example

```{r}
#Normalization
brain <- SCTransform(brain, assay = "Spatial", verbose = FALSE)
brain@assays$SCT
```

```{r}
#Dimension reduction
brain <- RunPCA(brain, assay = "SCT", verbose = FALSE)
brain <- FindNeighbors(brain, reduction = "pca", dims = 1:30)
brain <- RunUMAP(brain, reduction = "pca", dims = 1:30)
```


### Clustering 

![](images/Xiongetal-bioRxiv2025.png)

Probleme avec BayesSpace ??????

```{r}
#library(BayesSpace)
#diet.seurat = Seurat::DietSeurat(brain,
#                                   graphs = "SCT_nn",
#                                   dimreducs = c("pca"))
#sce_brain = as.SingleCellExperiment(diet.seurat, assay = "SCT") 
#colData(sce_brain) = cbind(colData(sce_brain),brain@images$anterior1$centroids@coords) 
#sce_brain = spatialPreprocess(sce_brain, 
#                          platform = "Visium",
#                          skip.PCA = T, 
#                          log.normalize = log.normalize) 
#sce_brain <- spatialCluster(sce_brain,
#                          nrep = 1000,
#                          q= 8,
#                          burn.in = 10,
#                          model = "t",
#                          gamma = 2)
#brain@meta.data[["bayes.space"]] <- as.factor(sce_brain$spatial.cluster)
```


```{r}
#InstallData("stxBrain")

##Seurat workflow
#brain = LoadData("stxBrain", type = "anterior1") #load seurat data
#brain = Seurat::FindVariableFeatures(brain) #Simple Seurat workflow for PCs
#brain <- SCTransform(brain, assay = "Spatial", verbose = FALSE)
#brain = Seurat::ScaleData(brain)
#brain = Seurat::RunPCA(brain)

##Convert to SCE
#diet.seurat = Seurat::DietSeurat(brain, graphs = "pca") #slim down #Seurat obj prior to conversion
#sce_brain = as.SingleCellExperiment(diet.seurat) #convert seurat to SCE
#colData(sce_brain) = cbind(colData(sce_brain), #brain@images$anterior1$centroids@coords) #add spatial info to SCE

##BayesSpace Workflow
#sce_brain = spatialPreprocess(sce_brain, platform = "Visium", skip.PCA = T, log.normalize = F) #add BayesSpace metadata, without messing with PCA/logcounts
#sce_brain = spatialCluster(sce_brain, nrep = 1000, burn.in = 100, q = 10) #quickly cluster via BayesSpace
#clusterPlot(sce_brain) #plot via BayesSpace

##Add BayesSpace results to Seurat
#brain@meta.data = cbind(brain@meta.data, BayesSpace = sce_brain$spatial.cluster) #add BayesSpace clusters to Seurat obj
#SpatialDimPlot(brain, "BayesSpace") #plot via Seurat


#https://www.ezstatconsulting.com/BayesSpace/articles/thrane_melanoma.html
```





### Appendix

- Commandes Seurat : https://satijalab.org/seurat/articles/essential_commands

